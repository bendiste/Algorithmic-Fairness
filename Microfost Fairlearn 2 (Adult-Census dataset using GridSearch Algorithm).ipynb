{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search (Mitigation Algorithm) with Adult/Census Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Census dataset is used to predict if an individual's income is below or above 50k per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.widget import FairlearnDashboard\n",
    "from sklearn.model_selection import train_test_split\n",
    "from fairlearn.reductions import GridSearch\n",
    "from fairlearn.reductions import DemographicParity, ErrorRate\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802.0</td>\n",
       "      <td>11th</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.0</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951.0</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103497.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>27.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302.0</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>40.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>58.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>22.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>52.0</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age     workclass    fnlwgt     education  education-num  \\\n",
       "0      25.0       Private  226802.0          11th            7.0   \n",
       "1      38.0       Private   89814.0       HS-grad            9.0   \n",
       "2      28.0     Local-gov  336951.0    Assoc-acdm           12.0   \n",
       "3      44.0       Private  160323.0  Some-college           10.0   \n",
       "4      18.0           NaN  103497.0  Some-college           10.0   \n",
       "...     ...           ...       ...           ...            ...   \n",
       "48837  27.0       Private  257302.0    Assoc-acdm           12.0   \n",
       "48838  40.0       Private  154374.0       HS-grad            9.0   \n",
       "48839  58.0       Private  151910.0       HS-grad            9.0   \n",
       "48840  22.0       Private  201490.0       HS-grad            9.0   \n",
       "48841  52.0  Self-emp-inc  287927.0       HS-grad            9.0   \n",
       "\n",
       "           marital-status         occupation relationship   race     sex  \\\n",
       "0           Never-married  Machine-op-inspct    Own-child  Black    Male   \n",
       "1      Married-civ-spouse    Farming-fishing      Husband  White    Male   \n",
       "2      Married-civ-spouse    Protective-serv      Husband  White    Male   \n",
       "3      Married-civ-spouse  Machine-op-inspct      Husband  Black    Male   \n",
       "4           Never-married                NaN    Own-child  White  Female   \n",
       "...                   ...                ...          ...    ...     ...   \n",
       "48837  Married-civ-spouse       Tech-support         Wife  White  Female   \n",
       "48838  Married-civ-spouse  Machine-op-inspct      Husband  White    Male   \n",
       "48839             Widowed       Adm-clerical    Unmarried  White  Female   \n",
       "48840       Never-married       Adm-clerical    Own-child  White    Male   \n",
       "48841  Married-civ-spouse    Exec-managerial         Wife  White  Female   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week native-country  \n",
       "0               0.0           0.0            40.0  United-States  \n",
       "1               0.0           0.0            50.0  United-States  \n",
       "2               0.0           0.0            40.0  United-States  \n",
       "3            7688.0           0.0            40.0  United-States  \n",
       "4               0.0           0.0            30.0  United-States  \n",
       "...             ...           ...             ...            ...  \n",
       "48837           0.0           0.0            38.0  United-States  \n",
       "48838           0.0           0.0            40.0  United-States  \n",
       "48839           0.0           0.0            40.0  United-States  \n",
       "48840           0.0           0.0            20.0  United-States  \n",
       "48841       15024.0           0.0            40.0  United-States  \n",
       "\n",
       "[48842 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = fetch_openml(data_id=1590, as_frame=True)\n",
    "X_raw = data.data\n",
    "Y = (data.target == '>50K') * 1\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        1\n",
       "3        1\n",
       "4        0\n",
       "        ..\n",
       "48837    0\n",
       "48838    1\n",
       "48839    0\n",
       "48840    0\n",
       "48841    1\n",
       "Name: class, Length: 48842, dtype: int32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in this setup, gender is the sensitive data and we are dropping that column from the dataset.\n",
    "A = X_raw[\"sex\"]\n",
    "X = X_raw.drop(labels=['sex'], axis=1)\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_scaled = sc.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split\n",
    "X_train, X_test, Y_train, Y_test, A_train, A_test = train_test_split(X_scaled,\n",
    "                                                                     Y,\n",
    "                                                                     A,\n",
    "                                                                     test_size=0.2,\n",
    "                                                                     random_state=0,\n",
    "                                                                     stratify=Y)\n",
    "\n",
    "# Work around indexing bug\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "A_train = A_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "A_test = A_test.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a fairness-unaware predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logistic regression\n",
    "unmitigated_predictor = LogisticRegression(solver='liblinear', fit_intercept=True)\n",
    "unmitigated_predictor.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hatta\\anaconda3\\lib\\site-packages\\fairlearn\\widget\\_fairlearn_dashboard.py:47: UserWarning: The FairlearnDashboard will move from Fairlearn to the raiwidgets package after the v0.5.0 release. Instead, Fairlearn will provide some of the existing functionality through matplotlib-based visualizations.\n",
      "  warn(\"The FairlearnDashboard will move from Fairlearn to the \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab507f8154804c2392893ad29a0469c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FairlearnWidget(value={'true_y': [0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<fairlearn.widget._fairlearn_dashboard.FairlearnDashboard at 0x23668ad83d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display of dashboard to investigate disparity\n",
    "FairlearnDashboard(sensitive_features=A_test, sensitive_feature_names=['sex'],\n",
    "                   y_true=Y_test,\n",
    "                   y_pred={\"unmitigated\": unmitigated_predictor.predict(X_test)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Result:__ Despite the fact that we removed the feature from the training data, our predictor still discriminates based on sex. This demonstrates that simply ignoring a sensitive feature when fitting a predictor rarely eliminates unfairness. There will generally be enough other features correlated with the removed feature to lead to disparate impact.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disparity mitigation with GridSearch algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user supplies a standard ML estimator to this algorithm, which is treated as a blackbox. GridSearch works by generating a sequence of relabellings and reweightings, and trains a predictor for each. Fairness metric is chosen as _demographic parity_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#takes ~5 mins to run\n",
    "sweep = GridSearch(LogisticRegression(solver='liblinear', fit_intercept=True),\n",
    "                   constraints=DemographicParity(),\n",
    "                   grid_size=71)\n",
    "#grid size gives the number of predictors calculated (The number of Lagrange multipliers to generate in the grid)\n",
    "sweep.fit(X_train, Y_train,\n",
    "          sensitive_features=A_train)\n",
    "\n",
    "predictors = sweep.predictors_\n",
    "predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could load these predictors into the Fairness dashboard now. However, the plot would be somewhat confusing due to their number. In this case, we are going to remove the predictors which are dominated in the error-disparity space by others from the sweep (note that the disparity will only be calculated for the sensitive feature; other potentially sensitive features will not be mitigated). In general, one might not want to do this, since there may be other considerations beyond the strict optimization of error and disparity (of the given sensitive feature). After eliminating the _dominated_ models, we can put the _dominant_ models into the Fairness dashboard, along with the unmitigated model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>error</th>\n",
       "      <th>disparity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.529496</td>\n",
       "      <td>0.458619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.525657</td>\n",
       "      <td>0.455768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.521357</td>\n",
       "      <td>0.453586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.517263</td>\n",
       "      <td>0.451892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.512733</td>\n",
       "      <td>0.449115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.354439</td>\n",
       "      <td>0.464455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.356410</td>\n",
       "      <td>0.465320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.357869</td>\n",
       "      <td>0.466213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.359302</td>\n",
       "      <td>0.466976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.360709</td>\n",
       "      <td>0.467895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 predictor     error  disparity\n",
       "0   LogisticRegression(solver='liblinear')  0.529496   0.458619\n",
       "1   LogisticRegression(solver='liblinear')  0.525657   0.455768\n",
       "2   LogisticRegression(solver='liblinear')  0.521357   0.453586\n",
       "3   LogisticRegression(solver='liblinear')  0.517263   0.451892\n",
       "4   LogisticRegression(solver='liblinear')  0.512733   0.449115\n",
       "..                                     ...       ...        ...\n",
       "66  LogisticRegression(solver='liblinear')  0.354439   0.464455\n",
       "67  LogisticRegression(solver='liblinear')  0.356410   0.465320\n",
       "68  LogisticRegression(solver='liblinear')  0.357869   0.466213\n",
       "69  LogisticRegression(solver='liblinear')  0.359302   0.466976\n",
       "70  LogisticRegression(solver='liblinear')  0.360709   0.467895\n",
       "\n",
       "[71 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors, disparities = [], []\n",
    "for m in predictors:\n",
    "    def classifier(X): return m.predict(X)\n",
    "    \n",
    "    error = ErrorRate()\n",
    "    #load_data loads the specified data into the object.\n",
    "    error.load_data(X_train, pd.Series(Y_train), sensitive_features=A_train)\n",
    "    disparity = DemographicParity()\n",
    "    disparity.load_data(X_train, pd.Series(Y_train), sensitive_features=A_train)\n",
    "\n",
    "    errors.append(error.gamma(classifier)[0])\n",
    "    disparities.append(disparity.gamma(classifier).max())\n",
    "\n",
    "all_results = pd.DataFrame({\"predictor\": predictors, \"error\": errors, \"disparity\": disparities})\n",
    "\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear'),\n",
       " LogisticRegression(solver='liblinear')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_dominated = []\n",
    "#itertuples() method will return an iterator yielding a named tuple for each row in the DataFrame. The first element of the tuple will be the rowâ€™s corresponding index value, while the remaining values are the row values.\n",
    "for row in all_results.itertuples():\n",
    "    errors_for_lower_or_eq_disparity = all_results[\"error\"][all_results[\"disparity\"] <= row.disparity]\n",
    "    if row.error <= errors_for_lower_or_eq_disparity.min():\n",
    "        non_dominated.append(row.predictor)\n",
    "non_dominated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hatta\\anaconda3\\lib\\site-packages\\fairlearn\\widget\\_fairlearn_dashboard.py:47: UserWarning: The FairlearnDashboard will move from Fairlearn to the raiwidgets package after the v0.5.0 release. Instead, Fairlearn will provide some of the existing functionality through matplotlib-based visualizations.\n",
      "  warn(\"The FairlearnDashboard will move from Fairlearn to the \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8829e4dd15054c31ba5e7883035ecfff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FairlearnWidget(value={'true_y': [0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<fairlearn.widget._fairlearn_dashboard.FairlearnDashboard at 0x2366ee22a90>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dashboard_predicted = {\"unmitigated\": unmitigated_predictor.predict(X_test)}\n",
    "for i in range(len(non_dominated)):\n",
    "    key = \"dominant_model_{0}\".format(i)\n",
    "    value = non_dominated[i].predict(X_test)\n",
    "    dashboard_predicted[key] = value\n",
    "\n",
    "\n",
    "FairlearnDashboard(sensitive_features=A_test, sensitive_feature_names=['sex'],\n",
    "                   y_true=Y_test,\n",
    "                   y_pred=dashboard_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.43014056e-01  6.35720604e-02  3.65265978e-01  2.39166162e+00\n",
      "   2.61677659e-01  3.40802299e-01  2.57827735e-01 -1.60706732e-02\n",
      "   1.14264676e-01  1.59363139e-01  1.17218860e-01  5.63478395e-02\n",
      "  -2.38846959e-02 -7.28564296e-02  1.48404021e-01  3.00457624e-02\n",
      "  -1.13295810e-01 -7.24179634e-02  1.16840154e-01  4.65145301e-03\n",
      "   1.47020107e-03 -8.32172035e-02 -1.19561131e-01 -6.02615097e-02\n",
      "   1.39117118e-01 -3.93332502e-02 -1.05010664e-01  1.02154497e-01\n",
      "  -3.25104525e-02 -3.37592118e-01  8.14181346e-01 -2.41227819e-01\n",
      "  -6.05837911e-01 -1.68868540e-01 -6.35956913e-03 -7.86656853e-02\n",
      "   4.45737100e-02  1.34171021e-01  4.72833726e-02 -1.59154391e-01\n",
      "   1.24821602e-01  3.21985213e-01  2.59885176e-01 -1.22663270e-01\n",
      "  -3.39335132e-02  9.68055098e-02 -1.32258367e-01 -6.03028401e-03\n",
      "  -1.09010767e-01  8.69631268e-02  2.74683156e-02  5.57524765e-01\n",
      "  -2.12959950e-01 -4.15130229e-01  2.26144285e-01 -9.81704263e-02\n",
      "   2.61065567e-01  2.16458117e-02  4.53509262e-02 -3.78409849e-02\n",
      "  -1.71427445e-02 -3.47808332e-02  1.05347857e-01  1.61489894e-02\n",
      "   4.51633686e-02 -3.41878138e-03  5.31189675e-02  1.22858262e-02\n",
      "  -1.28408401e-02 -2.05248124e-02  5.83900596e-03  1.02427062e-02\n",
      "  -4.28414877e-02 -1.61997621e-02  1.01954218e-02 -8.31660172e-03\n",
      "  -8.69716579e-04  4.40659468e-02  4.31262472e-02 -3.68025832e-03\n",
      "   2.45324688e-02 -2.28123601e-02 -7.77850912e-02  4.01629188e-02\n",
      "   4.55672539e-02  1.65758933e-02 -4.06581200e-02 -1.54001452e-01\n",
      "  -3.89594299e-03  6.19925640e-03  9.34765540e-03 -7.84184650e-02\n",
      "   1.42467048e-02 -1.65850873e-03 -2.21747129e-03 -2.74507875e-02\n",
      "  -1.50274017e-02  1.28891345e-02 -3.31888288e-02 -2.81764640e-02\n",
      "  -3.05357248e-02 -1.96570219e-02 -1.55206995e-02]]\n",
      "[[ 3.40166573e-01  6.85575497e-02  3.64518349e-01  2.37754743e+00\n",
      "   2.64850222e-01  3.45433389e-01  2.50986682e-01 -9.64450400e-03\n",
      "   1.17706010e-01  1.63771952e-01  1.07282036e-01  5.53390804e-02\n",
      "  -2.34931800e-02 -6.02165845e-02  1.50970269e-01  2.70863857e-02\n",
      "  -1.19518010e-01 -7.34217958e-02  1.21462931e-01  3.63225581e-03\n",
      "   5.30798553e-03 -8.37950431e-02 -1.20942334e-01 -5.76275293e-02\n",
      "   1.36537628e-01 -3.84625182e-02 -1.03343256e-01  1.01850179e-01\n",
      "  -3.32483299e-02 -3.12088007e-01  8.19449990e-01 -2.51088401e-01\n",
      "  -5.88366867e-01 -1.64171626e-01 -5.78384645e-02 -7.31196643e-02\n",
      "   4.56011923e-02  1.31614226e-01  6.46987080e-02 -1.78324757e-01\n",
      "   1.24191912e-01  3.16187401e-01  2.49410362e-01 -1.08713378e-01\n",
      "  -2.65376743e-02  7.91418839e-02 -1.29229041e-01  6.51284145e-03\n",
      "  -1.06257254e-01  9.41654209e-02  2.70234785e-02  3.73984896e-01\n",
      "  -2.21229406e-01 -2.70626522e-01  2.20644636e-01 -1.05740709e-01\n",
      "   1.79287046e-01  2.61143869e-02  4.59776613e-02 -3.51878867e-02\n",
      "  -1.46840558e-02 -4.21300586e-02  9.24109505e-02  1.90473724e-02\n",
      "   4.24242416e-02 -2.64698557e-03  5.19377167e-02  8.82683460e-03\n",
      "  -1.58925551e-02 -1.97184640e-02  3.18545106e-03  6.31012199e-03\n",
      "  -4.77209215e-02 -1.75615427e-02  8.12341172e-03 -6.66223901e-03\n",
      "   4.38693324e-04  3.83734681e-02  3.89114177e-02 -4.28698851e-03\n",
      "   2.34056770e-02 -2.09967893e-02 -7.90751770e-02  3.76792229e-02\n",
      "   4.39154629e-02  1.86186847e-02 -4.47996297e-02 -1.45470754e-01\n",
      "  -5.12184650e-03  4.92385801e-03  1.05315523e-02 -7.96767517e-02\n",
      "   9.62891470e-03  3.22238287e-04 -1.71836695e-04 -2.45653042e-02\n",
      "  -1.62104890e-02  1.27968026e-02 -3.20796135e-02 -2.80704131e-02\n",
      "  -2.72923042e-02 -2.18018896e-02 -1.56849087e-02]]\n"
     ]
    }
   ],
   "source": [
    "#check the difference between the feature coefficients assigned by the GridSearch algorithm\n",
    "print(non_dominated[0].coef_)\n",
    "\n",
    "print(non_dominated[2].coef_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Load all necessary packages\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
    "    import load_preproc_data_adult, load_preproc_data_german, load_preproc_data_compas\n",
    "\n",
    "from aif360.algorithms.preprocessing.lfr import LFR\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import dataset\n",
    "dataset_used = \"german\" # \"adult\", \"german\", \"compas\"\n",
    "protected_attribute_used = 2 # 1, 2\n",
    "\n",
    "if dataset_used == \"adult\":\n",
    "#    dataset_orig = AdultDataset()\n",
    "    dataset_orig = load_preproc_data_adult()\n",
    "    if protected_attribute_used == 1:\n",
    "        privileged_groups = [{'sex': 1}]\n",
    "        unprivileged_groups = [{'sex': 0}]\n",
    "    else:\n",
    "        privileged_groups = [{'race': 1}]\n",
    "        unprivileged_groups = [{'race': 0}]\n",
    "    \n",
    "elif dataset_used == \"german\":\n",
    "    dataset_orig = GermanDataset()\n",
    "    if protected_attribute_used == 1:\n",
    "        privileged_groups = [{'sex': 1}]\n",
    "        unprivileged_groups = [{'sex': 0}]\n",
    "    else:\n",
    "        privileged_groups = [{'age': 1}]\n",
    "        unprivileged_groups = [{'age': 0}]\n",
    "        \n",
    "    for i in range(1000):\n",
    "        if (dataset_orig.labels[i] == 2.0):\n",
    "            dataset_orig.labels[i] = 0\n",
    "        else:\n",
    "            dataset_orig.labels[i] = 1\n",
    "        \n",
    "    dataset_orig.favorable_label = 1\n",
    "    dataset_orig.unfavorable_label = 0\n",
    "\n",
    "    \n",
    "elif dataset_used == \"compas\":\n",
    "#     dataset_orig = CompasDataset()\n",
    "    dataset_orig = load_preproc_data_compas()\n",
    "    if protected_attribute_used == 1:\n",
    "        privileged_groups = [{'sex': 1}]\n",
    "        unprivileged_groups = [{'sex': 0}]\n",
    "    else:\n",
    "        privileged_groups = [{'race': 1}]\n",
    "        unprivileged_groups = [{'race': 0}] \n",
    "\n",
    "#Splitting train and test set\n",
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700\n"
     ]
    }
   ],
   "source": [
    "#It finds that if the dataset has a class imbalance, in terms of positive and negative outcomes.\n",
    "k=0\n",
    "for i in range(len(dataset_orig.labels)):\n",
    "    if(dataset_orig.labels[i] == 1):\n",
    "        k+=1\n",
    "    else:\n",
    "        pass\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Training Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 58)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Favorable and unfavorable labels"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Protected attribute names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex', 'age']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Privileged and unprivileged protected attribute values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.]), array([1.])] [array([0.]), array([0.])]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset feature names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['month', 'credit_amount', 'investment_as_income_percentage', 'residence_since', 'age', 'number_of_credits', 'people_liable_for', 'sex', 'status=A11', 'status=A12', 'status=A13', 'status=A14', 'credit_history=A30', 'credit_history=A31', 'credit_history=A32', 'credit_history=A33', 'credit_history=A34', 'purpose=A40', 'purpose=A41', 'purpose=A410', 'purpose=A42', 'purpose=A43', 'purpose=A44', 'purpose=A45', 'purpose=A46', 'purpose=A48', 'purpose=A49', 'savings=A61', 'savings=A62', 'savings=A63', 'savings=A64', 'savings=A65', 'employment=A71', 'employment=A72', 'employment=A73', 'employment=A74', 'employment=A75', 'other_debtors=A101', 'other_debtors=A102', 'other_debtors=A103', 'property=A121', 'property=A122', 'property=A123', 'property=A124', 'installment_plans=A141', 'installment_plans=A142', 'installment_plans=A143', 'housing=A151', 'housing=A152', 'housing=A153', 'skill_level=A171', 'skill_level=A172', 'skill_level=A173', 'skill_level=A174', 'telephone=A191', 'telephone=A192', 'foreign_worker=A201', 'foreign_worker=A202']\n"
     ]
    }
   ],
   "source": [
    "# some information of each dataset regarding labels, names, etc. \n",
    "display(Markdown(\"#### Training Dataset shape\"))\n",
    "print(dataset_orig_train.features.shape)\n",
    "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "display(Markdown(\"#### Protected attribute names\"))\n",
    "print(dataset_orig_train.protected_attribute_names)\n",
    "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "print(dataset_orig_train.privileged_protected_attributes, \n",
    "      dataset_orig_train.unprivileged_protected_attributes)\n",
    "display(Markdown(\"#### Dataset feature names\"))\n",
    "print(dataset_orig_train.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### german original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate impact (of original labels) between unprivileged and privileged groups = 0.744820\n",
      "Difference in statistical parity (of original labels) between unprivileged and privileged groups = -0.185911\n",
      "Individual fairness metric from Zemel et.al. that measures how similar the labels are for similar instances = 0.674571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_neighbors=5 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### german original test dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate impact (of original labels) between unprivileged and privileged groups = 0.900697\n",
      "Difference in statistical parity (of original labels) between unprivileged and privileged groups = -0.072296\n",
      "Individual fairness metric from Zemel et.al. that measures how similar the labels are for similar instances = 0.688000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_neighbors=5 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Initial disparities in the original datasets\n",
    "\n",
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "display(Markdown(\"#### %s original training dataset\"%dataset_used))\n",
    "print(\"Disparate impact (of original labels) between unprivileged and privileged groups = %f\" % metric_orig_train.disparate_impact())\n",
    "print(\"Difference in statistical parity (of original labels) between unprivileged and privileged groups = %f\" % metric_orig_train.statistical_parity_difference())\n",
    "print(\"Individual fairness metric from Zemel et.al. that measures how similar the labels are for similar instances = %f\" % metric_orig_train.consistency())\n",
    "\n",
    "metric_orig_test = BinaryLabelDatasetMetric(dataset_orig_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "display(Markdown(\"#### %s original test dataset\"%dataset_used))\n",
    "print(\"Disparate impact (of original labels) between unprivileged and privileged groups = %f\" % metric_orig_test.disparate_impact())\n",
    "print(\"Difference in statistical parity (of original labels) between unprivileged and privileged groups = %f\" % metric_orig_test.statistical_parity_difference())\n",
    "print(\"Individual fairness metric from Zemel et.al. that measures how similar the labels are for similar instances = %f\" % metric_orig_test.consistency())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling the dataset\n",
    "scale_orig = StandardScaler()\n",
    "\n",
    "X_train = scale_orig.fit_transform(dataset_orig_train.features)\n",
    "X_test = scale_orig.transform(dataset_orig_test.features)\n",
    "\n",
    "y_train = dataset_orig_train.labels.ravel()\n",
    "y_test = dataset_orig_test.labels.ravel()\n",
    "\n",
    "#Logistic Regression Training for each dataset\n",
    "log_reg = LogisticRegression() \n",
    "\n",
    "#Fitting the training set\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "#Predicting test set labels\n",
    "y_test_pred = log_reg.predict(X_test)\n",
    "y_test_pred_proba = log_reg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fairness performance of the predicted labels without mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### LR predictions of german Test Set: Fairness Performance Results"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average equalized odds difference between unprivileged and privileged groups = -0.209907\n",
      "Disparate impact ratio between unprivileged and privileged groups = 0.679659\n",
      "Demographic parity difference between unprivileged and privileged groups = -0.262707\n",
      "Predictive Parity difference between unprivileged and privileged groups = -0.081032\n",
      "Consistency of indivuals' predicted labels = 0.713333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_neighbors=5 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### LR Prediction Performance on german Test Set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard accuracy of logistic regression trained on German dataset without any mitigation = 0.753333\n",
      "Balanced accuracy of logistic regression trained on German dataset without any mitigation = 0.670615\n",
      "F1 score of logistic regression trained on German dataset without any mitigation = 0.833333\n",
      "For german dataset\n",
      "Precision (PPV): 0.804348\n",
      "Recall (TPR): 0.864486\n",
      "Specificity (TNR): 0.476744\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"#### LR predictions of %s Test Set: Fairness Performance Results\"%dataset_used))\n",
    "\n",
    "#Create a new version of the test set with predicted class labels\n",
    "testset_pred = dataset_orig_test.copy()\n",
    "testset_pred.labels = y_test_pred\n",
    "\n",
    "#Construction 1\n",
    "#to construct this metric function, the predicted labels should be united with the test fetures to make a new datas\n",
    "metric_pred_test = BinaryLabelDatasetMetric(testset_pred, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "#Construction 2\n",
    "#both original test dataset with actual labels and the test dataset combined with predicted class labels need to be given to this function\n",
    "classified_metric = ClassificationMetric(dataset_orig_test, \n",
    "                                                 testset_pred,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "\n",
    "\n",
    "#Checking Equalized Odds: average odds differecence, which is the avg. of differences in FPR&TPR for privileged and unprivileged groups.\n",
    "aeo = classified_metric.average_odds_difference()\n",
    "print(\"Average equalized odds difference between unprivileged and privileged groups = %f\" % aeo)\n",
    "\n",
    "#Disparate Impact ratio between privileged and unprivileged groups.\n",
    "di = classified_metric.disparate_impact()\n",
    "print(\"Disparate impact ratio between unprivileged and privileged groups = %f\" % di)\n",
    "\n",
    "#Demographic parity difference between privileged and unprivileged groups.\n",
    "spd = classified_metric.statistical_parity_difference()\n",
    "print(\"Demographic parity difference between unprivileged and privileged groups = %f\" % spd)\n",
    "\n",
    "#Predictive parity difference: PPV difference between privileged and unprivileged groups.\n",
    "ppd = classified_metric.positive_predictive_value(privileged=False) - classified_metric.positive_predictive_value(privileged=True)\n",
    "print(\"Predictive Parity difference between unprivileged and privileged groups = %f\" % ppd)\n",
    "\n",
    "#Individual Fairness: 1)Consistency, 2) Euclidean Distance between individuals.\n",
    "print(\"Consistency of indivuals' predicted labels = %f\" % metric_pred_test.consistency())\n",
    "\n",
    "TPR = classified_metric.true_positive_rate() #recall\n",
    "TNR = classified_metric.true_negative_rate() #specificity\n",
    "PPV = classified_metric.positive_predictive_value() #precision\n",
    "bal_acc = (TPR+TNR)/2\n",
    "f1 = 2*((PPV*TPR)/(PPV+TPR))\n",
    "\n",
    "display(Markdown(\"#### LR Prediction Performance on %s Test Set\"%dataset_used))\n",
    "print(\"Standard accuracy of logistic regression trained on German dataset without any mitigation = %f\" % classified_metric.accuracy())\n",
    "print(\"Balanced accuracy of logistic regression trained on German dataset without any mitigation = %f\" % bal_acc)\n",
    "print(\"F1 score of logistic regression trained on German dataset without any mitigation = %f\" % f1)\n",
    "\n",
    "print(\"For german dataset\")\n",
    "print(\"Precision (PPV): %f\" %PPV)\n",
    "print(\"Recall (TPR): %f\" %TPR)\n",
    "print(\"Specificity (TNR): %f\" %TNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1e8efaf0390>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_orig = confusion_matrix(dataset_orig_test.labels, testset_pred.labels)\n",
    "\n",
    "disp_orig = ConfusionMatrixDisplay(confusion_matrix=cm_orig,\n",
    "                              display_labels=log_reg.classes_)\n",
    "disp_orig.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of Learning Fair Represenrations Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\aif360\\algorithms\\preprocessing\\lfr_helpers\\helpers.py:62: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"LFR_optim_obj\" failed type inference due to: \u001b[1m\u001b[1mUnknown attribute 'iters' of type recursive(type(CPUDispatcher(<function LFR_optim_obj at 0x000001E896B0C9D8>)))\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\anaconda3\\envs\\aif360\\lib\\site-packages\\aif360\\algorithms\\preprocessing\\lfr_helpers\\helpers.py\", line 66:\u001b[0m\n",
      "\u001b[1mdef LFR_optim_obj(params, data_sensitive, data_nonsensitive, y_sensitive,\n",
      "    <source elided>\n",
      "\n",
      "\u001b[1m    LFR_optim_obj.iters += 1\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[1m[1] During: typing of get attribute at c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\aif360\\algorithms\\preprocessing\\lfr_helpers\\helpers.py (66)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\anaconda3\\envs\\aif360\\lib\\site-packages\\aif360\\algorithms\\preprocessing\\lfr_helpers\\helpers.py\", line 66:\u001b[0m\n",
      "\u001b[1mdef LFR_optim_obj(params, data_sensitive, data_nonsensitive, y_sensitive,\n",
      "    <source elided>\n",
      "\n",
      "\u001b[1m    LFR_optim_obj.iters += 1\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\aif360\\algorithms\\preprocessing\\lfr_helpers\\helpers.py:62: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"LFR_optim_obj\" failed type inference due to: \u001b[1m\u001b[1mcannot determine Numba type of <class 'numba.dispatcher.LiftedLoop'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\anaconda3\\envs\\aif360\\lib\\site-packages\\aif360\\algorithms\\preprocessing\\lfr_helpers\\helpers.py\", line 85:\u001b[0m\n",
      "\u001b[1mdef LFR_optim_obj(params, data_sensitive, data_nonsensitive, y_sensitive,\n",
      "    <source elided>\n",
      "    L_z = 0.0\n",
      "\u001b[1m    for j in range(k):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit\n",
      "c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\numba\\object_mode_passes.py:178: NumbaWarning: \u001b[1mFunction \"LFR_optim_obj\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\anaconda3\\envs\\aif360\\lib\\site-packages\\aif360\\algorithms\\preprocessing\\lfr_helpers\\helpers.py\", line 66:\u001b[0m\n",
      "\u001b[1mdef LFR_optim_obj(params, data_sensitive, data_nonsensitive, y_sensitive,\n",
      "    <source elided>\n",
      "\n",
      "\u001b[1m    LFR_optim_obj.iters += 1\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\numba\\object_mode_passes.py:188: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\anaconda3\\envs\\aif360\\lib\\site-packages\\aif360\\algorithms\\preprocessing\\lfr_helpers\\helpers.py\", line 66:\u001b[0m\n",
      "\u001b[1mdef LFR_optim_obj(params, data_sensitive, data_nonsensitive, y_sensitive,\n",
      "    <source elided>\n",
      "\n",
      "\u001b[1m    LFR_optim_obj.iters += 1\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 5429.2547597280745\n",
      "500 5181.880613027107\n",
      "750 5181.880690387563\n",
      "1000 5063.016636443756\n",
      "1250 5176.2366195427785\n",
      "1500 5176.236875121079\n",
      "1750 4719.054296809685\n",
      "2000 4719.054323682544\n",
      "2250 4397.456354985086\n",
      "2500 4684.0108847738675\n",
      "2750 4684.010943226902\n",
      "3000 4347.121806696803\n",
      "3250 4347.121920133898\n",
      "3500 4315.103935306959\n",
      "3750 4268.176217976064\n",
      "4000 4268.176281290303\n",
      "4250 4221.6372286150745\n",
      "4500 4221.637250793688\n",
      "4750 4176.656549597286\n",
      "5000 4199.117470580807\n",
      "5250 4199.117331902985\n",
      "5500 4167.0962727762835\n",
      "5750 4167.096116024622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\aif360\\algorithms\\preprocessing\\lfr_helpers\\helpers.py:50: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"yhat\" failed type inference due to: \u001b[1m\u001b[1mInvalid use of Function(<built-in function iadd>) with argument(s) of type(s): (float64, array(float64, 1d, C))\n",
      "Known signatures:\n",
      " * (int64, int64) -> int64\n",
      " * (int64, uint64) -> int64\n",
      " * (uint64, int64) -> int64\n",
      " * (uint64, uint64) -> uint64\n",
      " * (float32, float32) -> float32\n",
      " * (float64, float64) -> float64\n",
      " * (complex64, complex64) -> complex64\n",
      " * (complex128, complex128) -> complex128\n",
      " * parameterized\n",
      "\u001b[1mIn definition 0:\u001b[0m\n",
      "\u001b[1m    All templates rejected with literals.\u001b[0m\n",
      "\u001b[1mIn definition 1:\u001b[0m\n",
      "\u001b[1m    All templates rejected without literals.\u001b[0m\n",
      "\u001b[1mIn definition 2:\u001b[0m\n",
      "\u001b[1m    All templates rejected with literals.\u001b[0m\n",
      "\u001b[1mIn definition 3:\u001b[0m\n",
      "\u001b[1m    All templates rejected without literals.\u001b[0m\n",
      "\u001b[1mIn definition 4:\u001b[0m\n",
      "\u001b[1m    All templates rejected with literals.\u001b[0m\n",
      "\u001b[1mIn definition 5:\u001b[0m\n",
      "\u001b[1m    All templates rejected without literals.\u001b[0m\n",
      "\u001b[1mIn definition 6:\u001b[0m\n",
      "\u001b[1m    All templates rejected with literals.\u001b[0m\n",
      "\u001b[1mIn definition 7:\u001b[0m\n",
      "\u001b[1m    All templates rejected without literals.\u001b[0m\n",
      "\u001b[1mIn definition 8:\u001b[0m\n",
      "\u001b[1m    All templates rejected with literals.\u001b[0m\n",
      "\u001b[1mIn definition 9:\u001b[0m\n",
      "\u001b[1m    All templates rejected without literals.\u001b[0m\n",
      "\u001b[1mIn definition 10:\u001b[0m\n",
      "\u001b[1m    All templates rejected with literals.\u001b[0m\n",
      "\u001b[1mIn definition 11:\u001b[0m\n",
      "\u001b[1m    All templates rejected without literals.\u001b[0m\n",
      "\u001b[1mIn definition 12:\u001b[0m\n",
      "\u001b[1m    All templates rejected with literals.\u001b[0m\n",
      "\u001b[1mIn definition 13:\u001b[0m\n",
      "\u001b[1m    All templates rejected without literals.\u001b[0m\n",
      "\u001b[1mIn definition 14:\u001b[0m\n",
      "\u001b[1m    All templates rejected with literals.\u001b[0m\n",
      "\u001b[1mIn definition 15:\u001b[0m\n",
      "\u001b[1m    All templates rejected without literals.\u001b[0m\n",
      "\u001b[1mThis error is usually caused by passing an argument of a type that is unsupported by the named function.\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1m[1] During: typing of intrinsic-call at c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\aif360\\algorithms\\preprocessing\\lfr_helpers\\helpers.py (59)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\anaconda3\\envs\\aif360\\lib\\site-packages\\aif360\\algorithms\\preprocessing\\lfr_helpers\\helpers.py\", line 59:\u001b[0m\n",
      "\u001b[1mdef yhat(M_nk, y, w, N, k):\n",
      "    <source elided>\n",
      "        yhat[i] = 0.999 if yhat[i] >= 1 else yhat[i]\n",
      "\u001b[1m        L_y += -1 * y[i] * np.log(yhat[i]) - (1.0 - y[i]) * np.log(1.0 - yhat[i])\n",
      "\u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\aif360\\algorithms\\preprocessing\\lfr_helpers\\helpers.py:50: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"yhat\" failed type inference due to: \u001b[1m\u001b[1mcannot determine Numba type of <class 'numba.dispatcher.LiftedLoop'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\anaconda3\\envs\\aif360\\lib\\site-packages\\aif360\\algorithms\\preprocessing\\lfr_helpers\\helpers.py\", line 54:\u001b[0m\n",
      "\u001b[1mdef yhat(M_nk, y, w, N, k):\n",
      "    <source elided>\n",
      "    L_y = 0.0\n",
      "\u001b[1m    for i in range(N):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit\n",
      "c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\numba\\object_mode_passes.py:178: NumbaWarning: \u001b[1mFunction \"yhat\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\anaconda3\\envs\\aif360\\lib\\site-packages\\aif360\\algorithms\\preprocessing\\lfr_helpers\\helpers.py\", line 52:\u001b[0m\n",
      "\u001b[1mdef yhat(M_nk, y, w, N, k):\n",
      "\u001b[1m    yhat = np.zeros(N)\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\numba\\object_mode_passes.py:188: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\anaconda3\\envs\\aif360\\lib\\site-packages\\aif360\\algorithms\\preprocessing\\lfr_helpers\\helpers.py\", line 52:\u001b[0m\n",
      "\u001b[1mdef yhat(M_nk, y, w, N, k):\n",
      "\u001b[1m    yhat = np.zeros(N)\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\aif360\\algorithms\\preprocessing\\lfr_helpers\\helpers.py:50: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"yhat\" failed type inference due to: \u001b[1m\u001b[1mInvalid use of Function(<built-in function iadd>) with argument(s) of type(s): (float64, array(float64, 1d, C))\n",
      "Known signatures:\n",
      " * (int64, int64) -> int64\n",
      " * (int64, uint64) -> int64\n",
      " * (uint64, int64) -> int64\n",
      " * (uint64, uint64) -> uint64\n",
      " * (float32, float32) -> float32\n",
      " * (float64, float64) -> float64\n",
      " * (complex64, complex64) -> complex64\n",
      " * (complex128, complex128) -> complex128\n",
      " * parameterized\n",
      "\u001b[1mIn definition 0:\u001b[0m\n",
      "\u001b[1m    All templates rejected with literals.\u001b[0m\n",
      "\u001b[1mIn definition 1:\u001b[0m\n",
      "\u001b[1m    All templates rejected without literals.\u001b[0m\n",
      "\u001b[1mIn definition 2:\u001b[0m\n",
      "\u001b[1m    All templates rejected with literals.\u001b[0m\n",
      "\u001b[1mIn definition 3:\u001b[0m\n",
      "\u001b[1m    All templates rejected without literals.\u001b[0m\n",
      "\u001b[1mIn definition 4:\u001b[0m\n",
      "\u001b[1m    All templates rejected with literals.\u001b[0m\n",
      "\u001b[1mIn definition 5:\u001b[0m\n",
      "\u001b[1m    All templates rejected without literals.\u001b[0m\n",
      "\u001b[1mIn definition 6:\u001b[0m\n",
      "\u001b[1m    All templates rejected with literals.\u001b[0m\n",
      "\u001b[1mIn definition 7:\u001b[0m\n",
      "\u001b[1m    All templates rejected without literals.\u001b[0m\n",
      "\u001b[1mIn definition 8:\u001b[0m\n",
      "\u001b[1m    All templates rejected with literals.\u001b[0m\n",
      "\u001b[1mIn definition 9:\u001b[0m\n",
      "\u001b[1m    All templates rejected without literals.\u001b[0m\n",
      "\u001b[1mIn definition 10:\u001b[0m\n",
      "\u001b[1m    All templates rejected with literals.\u001b[0m\n",
      "\u001b[1mIn definition 11:\u001b[0m\n",
      "\u001b[1m    All templates rejected without literals.\u001b[0m\n",
      "\u001b[1mIn definition 12:\u001b[0m\n",
      "\u001b[1m    All templates rejected with literals.\u001b[0m\n",
      "\u001b[1mIn definition 13:\u001b[0m\n",
      "\u001b[1m    All templates rejected without literals.\u001b[0m\n",
      "\u001b[1mIn definition 14:\u001b[0m\n",
      "\u001b[1m    All templates rejected with literals.\u001b[0m\n",
      "\u001b[1mIn definition 15:\u001b[0m\n",
      "\u001b[1m    All templates rejected without literals.\u001b[0m\n",
      "\u001b[1mThis error is usually caused by passing an argument of a type that is unsupported by the named function.\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1m[1] During: typing of intrinsic-call at c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\aif360\\algorithms\\preprocessing\\lfr_helpers\\helpers.py (59)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\anaconda3\\envs\\aif360\\lib\\site-packages\\aif360\\algorithms\\preprocessing\\lfr_helpers\\helpers.py\", line 59:\u001b[0m\n",
      "\u001b[1mdef yhat(M_nk, y, w, N, k):\n",
      "    <source elided>\n",
      "        yhat[i] = 0.999 if yhat[i] >= 1 else yhat[i]\n",
      "\u001b[1m        L_y += -1 * y[i] * np.log(yhat[i]) - (1.0 - y[i]) * np.log(1.0 - yhat[i])\n",
      "\u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\numba\\object_mode_passes.py:178: NumbaWarning: \u001b[1mFunction \"yhat\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\anaconda3\\envs\\aif360\\lib\\site-packages\\aif360\\algorithms\\preprocessing\\lfr_helpers\\helpers.py\", line 54:\u001b[0m\n",
      "\u001b[1mdef yhat(M_nk, y, w, N, k):\n",
      "    <source elided>\n",
      "    L_y = 0.0\n",
      "\u001b[1m    for i in range(N):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\numba\\object_mode_passes.py:188: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\anaconda3\\envs\\aif360\\lib\\site-packages\\aif360\\algorithms\\preprocessing\\lfr_helpers\\helpers.py\", line 54:\u001b[0m\n",
      "\u001b[1mdef yhat(M_nk, y, w, N, k):\n",
      "    <source elided>\n",
      "    L_y = 0.0\n",
      "\u001b[1m    for i in range(N):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n"
     ]
    }
   ],
   "source": [
    "#1) Transforming Adult Dataset\n",
    "\n",
    "#Required Inputs:\n",
    "# Input recontruction quality - Ax\n",
    "# Fairness constraint - Az\n",
    "# Output prediction error - Ay\n",
    "\n",
    "#scaled dataset together with its labels is needed\n",
    "dataset_orig_train.features = scale_orig.fit_transform(dataset_orig_train.features)\n",
    "dataset_orig_test.features = scale_orig.transform(dataset_orig_test.features)\n",
    "\n",
    "#LFR itself contains logistic regression sinc it uses signoid functions \n",
    "LFR =LFR(unprivileged_groups=unprivileged_groups,\n",
    "         privileged_groups=privileged_groups,\n",
    "         k=5, Ax=0.1, Ay=1.0, Az=100.0, verbose=1)\n",
    "\n",
    "TR = LFR.fit(dataset_orig_train, maxiter=5000, maxfun=5000)\n",
    "\n",
    "# Transform training data and align features\n",
    "dataset_transf_train = TR.transform(dataset_orig_train)\n",
    "#a_transf_test = TR_a.transform(adult_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if the labels are transformed: counts the num. of transformed labels\n",
    "k=0\n",
    "for i in range(len(dataset_orig_train.labels)):\n",
    "    if(dataset_transf_train.labels[i] == dataset_orig_train.labels[i]):\n",
    "        pass\n",
    "    else:\n",
    "        k+=1\n",
    "        \n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copying transformed features and pasting original labels to them\n",
    "transf_train_new = dataset_orig_train.copy(deepcopy=True)\n",
    "transf_train_new.scores = dataset_transf_train.scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of LFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Transformed german train set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate impact ratio (of transformed labels) between unprivileged and privileged groups = 1.000262\n",
      "Difference in statistical parity (of transformed labels) between unprivileged and privileged groups = 0.000258\n",
      "Individual fairness metric 'consistency' that measures how similar the labels are for similar instances = 0.998000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_neighbors=5 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Fairness Performance of Datasets Before Classification\n",
    "\n",
    "#Constucting two functions to call the desired metrics\n",
    "metric_transf_train = BinaryLabelDatasetMetric(dataset_transf_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "display(Markdown(\"#### Transformed %s train set\"%dataset_used))\n",
    "print(\"Disparate impact ratio (of transformed labels) between unprivileged and privileged groups = %f\" % metric_transf_train.disparate_impact())\n",
    "print(\"Difference in statistical parity (of transformed labels) between unprivileged and privileged groups = %f\" % metric_transf_train.statistical_parity_difference())\n",
    "print(\"Individual fairness metric 'consistency' that measures how similar the labels are for similar instances = %f\" % metric_transf_train.consistency())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training logistic regression with transformed dataset and predicting test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trans =dataset_transf_train.features\n",
    "X_test_trans = dataset_orig_test.features\n",
    "\n",
    "y_train_trans = dataset_transf_train.labels.ravel()\n",
    "y_test_trans = dataset_orig_test.labels.ravel() \n",
    "\n",
    "\n",
    "#Logistic Regression Training with the transformed dataset\n",
    "trans_lr = LogisticRegression()\n",
    "\n",
    "#fitting the model\n",
    "trans_lr.fit(X_train_trans, y_train_trans)\n",
    "\n",
    "#Predicting test set labels\n",
    "y_test_trans_pred = trans_lr.predict(X_test_trans)\n",
    "y_test_trans_pred_proba = trans_lr.predict_proba(X_test_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new version of the transformed test set with predicted class labels\n",
    "testset_pred_trans = dataset_orig_test.copy()\n",
    "testset_pred_trans.labels = y_test_trans_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### (Pre-processed) LR with german Test Set Fairness Performance (based on predictions)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average equalized odds difference between unprivileged and privileged groups = 0.048939\n",
      "Disparate impact ratio between unprivileged and privileged groups = 1.052863\n",
      "Demographic parity difference between unprivileged and privileged groups = 0.050209\n",
      "Predictive Parity difference between unprivileged and privileged groups = -0.071135\n",
      "Consistency of indivuals' predicted labels = 0.964000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_neighbors=5 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### (Pre-processed) LR with german Test Set Prediction Performance"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard accuracy of logistic regression trained on test set with debiasing = 0.693333\n",
      "Balanced accuracy of logistic regression trained on test set  with debiasing = 0.496414\n",
      "F1 score of logistic regression trained on test set with debiasing = 0.816733\n",
      "Detailed scores for german test set\n",
      "Precision (PPV): 0.711806\n",
      "Recall (TPR): 0.957944\n",
      "Specificity (TNR): 0.034884\n"
     ]
    }
   ],
   "source": [
    "#Performance Metrics from the dataset predictions\n",
    "\n",
    "metric_trans_test = BinaryLabelDatasetMetric(testset_pred_trans, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "classified_trans_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 testset_pred_trans,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "\n",
    "\n",
    "display(Markdown(\"#### (Pre-processed) LR with %s Test Set Fairness Performance (based on predictions)\"%dataset_used))\n",
    "\n",
    "#Checking Equalized Odds: average odds differecence, which is the avg. of differences in FPR&TPR for privileged and unprivileged groups.\n",
    "deb_aeo_t = classified_trans_test.average_odds_difference()\n",
    "print(\"Average equalized odds difference between unprivileged and privileged groups = %f\" % deb_aeo_t)\n",
    "\n",
    "#Disparate Impact ratio between privileged and unprivileged groups.\n",
    "deb_di_t = classified_trans_test.disparate_impact()\n",
    "print(\"Disparate impact ratio between unprivileged and privileged groups = %f\" % deb_di_t)\n",
    "\n",
    "#Demographic parity difference between privileged and unprivileged groups.\n",
    "deb_spd_t = classified_trans_test.statistical_parity_difference()\n",
    "print(\"Demographic parity difference between unprivileged and privileged groups = %f\" % deb_spd_t)\n",
    "\n",
    "#Predictive parity difference: PPV difference between privileged and unprivileged groups.\n",
    "deb_ppd_t = classified_trans_test.positive_predictive_value(privileged=False) - classified_trans_test.positive_predictive_value(privileged=True)\n",
    "print(\"Predictive Parity difference between unprivileged and privileged groups = %f\" % deb_ppd_t)\n",
    "\n",
    "#Individual Fairness: 1)Consistency, 2) Euclidean Distance between individuals.\n",
    "print(\"Consistency of indivuals' predicted labels = %f\" % metric_trans_test.consistency())\n",
    "\n",
    "\n",
    "#Prediction performance metrics\n",
    "TPR_t = classified_trans_test.true_positive_rate() #recall\n",
    "TNR_t = classified_trans_test.true_negative_rate() #specificity\n",
    "PPV_t = classified_trans_test.positive_predictive_value() #precision\n",
    "bal_acc_t = (TPR_t+TNR_t)/2\n",
    "f1_t = 2*((PPV_t*TPR_t)/(PPV_t+TPR_t))\n",
    "\n",
    "display(Markdown(\"#### (Pre-processed) LR with %s Test Set Prediction Performance\"%dataset_used))\n",
    "print(\"Standard accuracy of logistic regression trained on test set with debiasing = %f\" % classified_trans_test.accuracy())\n",
    "print(\"Balanced accuracy of logistic regression trained on test set  with debiasing = %f\" % bal_acc_t)\n",
    "print(\"F1 score of logistic regression trained on test set with debiasing = %f\" % f1_t)\n",
    "\n",
    "print(\"Detailed scores for %s test set\"%dataset_used)\n",
    "print(\"Precision (PPV): %f\" %PPV_t)\n",
    "print(\"Recall (TPR): %f\" %TPR_t)\n",
    "print(\"Specificity (TNR): %f\" %TNR_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1e89c59ba58>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_trans = confusion_matrix(dataset_orig_test.labels, testset_pred_trans.labels)\n",
    "\n",
    "disp_trans = ConfusionMatrixDisplay(confusion_matrix=cm_trans,\n",
    "                              display_labels=trans_lr.classes_)\n",
    "disp_trans.plot() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

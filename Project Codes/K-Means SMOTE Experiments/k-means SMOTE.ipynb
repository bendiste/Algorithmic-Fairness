{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalanced Learning with SMOTE Variants (K-means, Borderline etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kmodes\n",
      "  Downloading kmodes-0.11.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages (from kmodes) (0.24.1)\n",
      "Requirement already satisfied: scipy>=0.13.3 in c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages (from kmodes) (1.5.4)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages (from kmodes) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.10.4 in c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages (from kmodes) (1.18.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages (from scikit-learn>=0.22.0->kmodes) (2.1.0)\n",
      "Installing collected packages: kmodes\n",
      "Successfully installed kmodes-0.11.0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "If you wish to download these packages into the same virtual environment as aif360, you can use the following commands in \n",
    "Jupyter notebook:\n",
    "!pip install -U imbalanced-learn\n",
    "!pip install smote_variants\n",
    "'''\n",
    "\n",
    "!pip install --upgrade kmodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "import mlrose\n",
    "'''because of the version conflicts of sklearn and imblearn, I had to import six separately (because sklearn depreciated utils.six\n",
    "in the version 0.23 and I am using 0.24). Imblearn gives a lot of conflicts with sklearn if you install any version lower than 0.8'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.datasets import fetch_datasets\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, KMeansSMOTE, SVMSMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn import FunctionSampler  # to use a idendity sampler\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets import StructuredDataset\n",
    "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "#from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
    "    import load_preproc_data_adult, load_preproc_data_german, load_preproc_data_compas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example imbalanced dataset label count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class -1 has 896 instances\n",
      "Class 1 has 41 instances\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = fetch_datasets(filter_data=['oil'])\n",
    "X, y = datasets['oil']['data'], datasets['oil']['target']\n",
    "\n",
    "[print('Class {} has {} instances'.format(label, count))\n",
    " for label, count in zip(*np.unique(y, return_counts=True))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using fairness dataset with imbalanced learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import dataset\n",
    "dataset_used = \"adult\" # \"adult\", \"german\", \"compas\"\n",
    "protected_attribute_used = 1 # 1, 2\n",
    "\n",
    "if dataset_used == \"adult\":\n",
    "#    dataset_orig = AdultDataset()\n",
    "    dataset_orig = load_preproc_data_adult()\n",
    "    if protected_attribute_used == 1:\n",
    "        privileged_groups = [{'sex': 1}]\n",
    "        unprivileged_groups = [{'sex': 0}]\n",
    "    else:\n",
    "        privileged_groups = [{'race': 1}]\n",
    "        unprivileged_groups = [{'race': 0}]\n",
    "    \n",
    "elif dataset_used == \"german\":\n",
    "    dataset_orig = GermanDataset()\n",
    "    if protected_attribute_used == 1:\n",
    "        privileged_groups = [{'sex': 1}]\n",
    "        unprivileged_groups = [{'sex': 0}]\n",
    "    else:\n",
    "        privileged_groups = [{'age': 1}]\n",
    "        unprivileged_groups = [{'age': 0}]\n",
    "        \n",
    "    for i in range(1000):\n",
    "        if (dataset_orig.labels[i] == 2.0):\n",
    "            dataset_orig.labels[i] = 0\n",
    "        else:\n",
    "            dataset_orig.labels[i] = 1\n",
    "        \n",
    "    dataset_orig.favorable_label = 1\n",
    "    dataset_orig.unfavorable_label = 0\n",
    "\n",
    "    \n",
    "elif dataset_used == \"compas\":\n",
    "#     dataset_orig = CompasDataset()\n",
    "    dataset_orig = load_preproc_data_compas()\n",
    "    if protected_attribute_used == 1:\n",
    "        privileged_groups = [{'sex': 1}]\n",
    "        unprivileged_groups = [{'sex': 0}]\n",
    "    else:\n",
    "        privileged_groups = [{'race': 1}]\n",
    "        unprivileged_groups = [{'race': 0}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['race',\n",
       " 'sex',\n",
       " 'Age (decade)=10',\n",
       " 'Age (decade)=20',\n",
       " 'Age (decade)=30',\n",
       " 'Age (decade)=40',\n",
       " 'Age (decade)=50',\n",
       " 'Age (decade)=60',\n",
       " 'Age (decade)=>=70',\n",
       " 'Education Years=6',\n",
       " 'Education Years=7',\n",
       " 'Education Years=8',\n",
       " 'Education Years=9',\n",
       " 'Education Years=10',\n",
       " 'Education Years=11',\n",
       " 'Education Years=12',\n",
       " 'Education Years=<6',\n",
       " 'Education Years=>12']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_orig.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### adult original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate impact (of original labels) between unprivileged and privileged groups = 0.359655\n",
      "Difference in statistical parity (of original labels) between unprivileged and privileged groups = -0.194516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass n_neighbors=5 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual fairness metric from Zemel et.al. that measures how similar the labels are for similar instances = 0.756660\n"
     ]
    }
   ],
   "source": [
    "# Initial disparities in the original datasets\n",
    "\n",
    "metric_orig = BinaryLabelDatasetMetric(dataset_orig, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "display(Markdown(\"#### %s original training dataset\"%dataset_used))\n",
    "print(\"Disparate impact (of original labels) between unprivileged and privileged groups = %f\" % metric_orig.disparate_impact())\n",
    "print(\"Difference in statistical parity (of original labels) between unprivileged and privileged groups = %f\" % metric_orig.statistical_parity_difference())\n",
    "print(\"Individual fairness metric from Zemel et.al. that measures how similar the labels are for similar instances = %f\" % metric_orig.consistency())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.760718\n",
       "1.0    0.239282\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_X = dataset_orig.features\n",
    "dataset_y = dataset_orig.labels.ravel()\n",
    "y_pandas = pd.Series(dataset_y)\n",
    "\n",
    "#Check the ratio of class imbalance\n",
    "y_pandas.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0.0 has 37155 instances\n",
      "Class 1.0 has 11687 instances\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Class counts\n",
    "[print('Class {} has {} instances'.format(label, count))\n",
    " for label, count in zip(*np.unique(dataset_y, return_counts=True))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-test split\n",
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)\n",
    "\n",
    "X_train = dataset_orig_train.features\n",
    "X_test = dataset_orig_test.features\n",
    "\n",
    "y_train = dataset_orig_train.labels.ravel()\n",
    "y_test = dataset_orig_test.labels.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training classifiers to check the predicted performance with imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "num_pipe = make_pipeline(\n",
    "    StandardScaler(), SimpleImputer(strategy=\"mean\", add_indicator=True)\n",
    ")\n",
    "\n",
    "index = []\n",
    "scores = {\"Accuracy\": [], \"Balanced accuracy\": []}\n",
    "\n",
    "\n",
    "ind = []\n",
    "results = {\"AEO Difference\": [], \"Disparate Impact Ratio\": [], \"Dem Parity Difference\": [], \"Predictive Parity Difference\": [],\n",
    "           \"Consistency\": [],  \"Accuracy\": [], \"Balanced accuracy\": [],  \"F1-Score\": []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic regression</th>\n",
       "      <td>0.804042</td>\n",
       "      <td>0.660557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy  Balanced accuracy\n",
       "Logistic regression  0.804042           0.660557"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scoring = [\"accuracy\", \"balanced_accuracy\"]\n",
    "lr_clf = make_pipeline(num_pipe, LogisticRegression(max_iter=1000))\n",
    "\n",
    "index += [\"Logistic regression\"]\n",
    "cv_result = cross_validate(lr_clf, dataset_X, dataset_y, scoring=scoring, return_estimator=True)\n",
    "scores[\"Accuracy\"].append(cv_result[\"test_accuracy\"].mean())\n",
    "scores[\"Balanced accuracy\"].append(cv_result[\"test_balanced_accuracy\"].mean())\n",
    "\n",
    "df_scores = pd.DataFrame(scores, index=index)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.21156502, 0.1884532 , 0.2089653 , 0.21659517, 0.23473287]),\n",
       " 'score_time': array([0.03127265, 0.03241754, 0.02500296, 0.04905057, 0.0469532 ]),\n",
       " 'estimator': [Pipeline(steps=[('pipeline',\n",
       "                   Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                   ('simpleimputer',\n",
       "                                    SimpleImputer(add_indicator=True))])),\n",
       "                  ('logisticregression', LogisticRegression(max_iter=1000))]),\n",
       "  Pipeline(steps=[('pipeline',\n",
       "                   Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                   ('simpleimputer',\n",
       "                                    SimpleImputer(add_indicator=True))])),\n",
       "                  ('logisticregression', LogisticRegression(max_iter=1000))]),\n",
       "  Pipeline(steps=[('pipeline',\n",
       "                   Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                   ('simpleimputer',\n",
       "                                    SimpleImputer(add_indicator=True))])),\n",
       "                  ('logisticregression', LogisticRegression(max_iter=1000))]),\n",
       "  Pipeline(steps=[('pipeline',\n",
       "                   Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                   ('simpleimputer',\n",
       "                                    SimpleImputer(add_indicator=True))])),\n",
       "                  ('logisticregression', LogisticRegression(max_iter=1000))]),\n",
       "  Pipeline(steps=[('pipeline',\n",
       "                   Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                   ('simpleimputer',\n",
       "                                    SimpleImputer(add_indicator=True))])),\n",
       "                  ('logisticregression', LogisticRegression(max_iter=1000))])],\n",
       " 'test_accuracy': array([0.80049135, 0.80223155, 0.80436118, 0.80733006, 0.80579443]),\n",
       " 'test_balanced_accuracy': array([0.65515776, 0.66099193, 0.66124779, 0.66407906, 0.66130981])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### LR predictions of adult Test Set: Fairness Performance Results"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass n_neighbors=5 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### LR Prediction Performance on adult Test Set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For adult dataset\n",
      "Precision (PPV): 0.650163\n",
      "Recall (TPR): 0.402196\n",
      "Specificity (TNR): 0.933077\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Training for each dataset\n",
    "log_reg = LogisticRegression() \n",
    "\n",
    "#Fitting the training set\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_test_pred = log_reg.predict(X_test)\n",
    "\n",
    "display(Markdown(\"#### LR predictions of %s Test Set: Fairness Performance Results\"%dataset_used))\n",
    "\n",
    "#Create a new version of the test set with predicted class labels\n",
    "testset_pred = dataset_orig_test.copy()\n",
    "testset_pred.labels = y_test_pred\n",
    "\n",
    "#Construction 1\n",
    "#to construct this metric function, the predicted labels should be united with the test fetures to make a new datas\n",
    "metric_pred_test = BinaryLabelDatasetMetric(testset_pred, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "#Construction 2\n",
    "#both original test dataset with actual labels and the test dataset combined with predicted class labels need to be given to this function\n",
    "classified_metric = ClassificationMetric(dataset_orig_test, \n",
    "                                                 testset_pred,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "\n",
    "\n",
    "#Checking Equalized Odds: average odds differecence, which is the avg. of differences in FPR&TPR for privileged and unprivileged groups.\n",
    "aeo = classified_metric.average_odds_difference()\n",
    "\n",
    "#Disparate Impact ratio between privileged and unprivileged groups.\n",
    "di = classified_metric.disparate_impact()\n",
    "\n",
    "#Demographic parity difference between privileged and unprivileged groups.\n",
    "spd = classified_metric.statistical_parity_difference()\n",
    "\n",
    "#Predictive parity difference: PPV difference between privileged and unprivileged groups.\n",
    "ppd = classified_metric.positive_predictive_value(privileged=False) - classified_metric.positive_predictive_value(privileged=True)\n",
    "\n",
    "#Individual Fairness: 1)Consistency, 2) Euclidean Distance between individuals.\n",
    "consistency = metric_pred_test.consistency()\n",
    "\n",
    "TPR = classified_metric.true_positive_rate() #recall\n",
    "TNR = classified_metric.true_negative_rate() #specificity\n",
    "PPV = classified_metric.positive_predictive_value() #precision\n",
    "bal_acc = (TPR+TNR)/2\n",
    "f1 = 2*((PPV*TPR)/(PPV+TPR))\n",
    "acc = classified_metric.accuracy()\n",
    "\n",
    "ind += [\"Log reg imb test set\"]\n",
    "results[\"AEO Difference\"].append(aeo)\n",
    "results[\"Disparate Impact Ratio\"].append(di)\n",
    "results[\"Dem Parity Difference\"].append(spd)\n",
    "results[\"Predictive Parity Difference\"].append(ppd)\n",
    "results[\"Consistency\"].append(consistency)\n",
    "results[\"Accuracy\"].append(acc)\n",
    "results[\"Balanced accuracy\"].append(bal_acc)\n",
    "results[\"F1-Score\"].append(f1)\n",
    "          \n",
    "df_results = pd.DataFrame(results, index=ind)\n",
    "    \n",
    "display(Markdown(\"#### LR Prediction Performance on %s Test Set\"%dataset_used))\n",
    "\n",
    "print(\"For %s dataset\"%dataset_used)\n",
    "print(\"Precision (PPV): %f\" %PPV)\n",
    "print(\"Recall (TPR): %f\" %TPR)\n",
    "print(\"Specificity (TNR): %f\" %TNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AEO Difference</th>\n",
       "      <th>Disparate Impact Ratio</th>\n",
       "      <th>Dem Parity Difference</th>\n",
       "      <th>Predictive Parity Difference</th>\n",
       "      <th>Consistency</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Log reg imb test set</th>\n",
       "      <td>-0.288414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.21714</td>\n",
       "      <td>-0.650163</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.807684</td>\n",
       "      <td>0.667637</td>\n",
       "      <td>0.496965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      AEO Difference  Disparate Impact Ratio  \\\n",
       "Log reg imb test set       -0.288414                     0.0   \n",
       "\n",
       "                      Dem Parity Difference  Predictive Parity Difference  \\\n",
       "Log reg imb test set               -0.21714                     -0.650163   \n",
       "\n",
       "                      Consistency  Accuracy  Balanced accuracy  F1-Score  \n",
       "Log reg imb test set          1.0  0.807684           0.667637  0.496965  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic regression</th>\n",
       "      <td>0.804042</td>\n",
       "      <td>0.660557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.803284</td>\n",
       "      <td>0.663226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy  Balanced accuracy\n",
       "Logistic regression  0.804042           0.660557\n",
       "Random forest        0.803284           0.663226"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = make_pipeline(\n",
    "   num_pipe, RandomForestClassifier(random_state=42, n_jobs=2)\n",
    ")\n",
    "index += [\"Random forest\"]\n",
    "cv_result = cross_validate(rf_clf, dataset_X, dataset_y, scoring=scoring)\n",
    "scores[\"Accuracy\"].append(cv_result[\"test_accuracy\"].mean())\n",
    "scores[\"Balanced accuracy\"].append(cv_result[\"test_balanced_accuracy\"].mean())\n",
    "\n",
    "df_scores = pd.DataFrame(scores, index=index)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### RFC predictions of adult Test Set: Fairness Performance Results"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass n_neighbors=5 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### RF Prediction Performance on adult Test Set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For adult dataset\n",
      "Precision (PPV): 0.628918\n",
      "Recall (TPR): 0.434845\n",
      "Specificity (TNR): 0.920658\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(random_state=42, n_jobs=2)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_test_pred = rfc.predict(X_test)\n",
    "\n",
    "display(Markdown(\"#### RFC predictions of %s Test Set: Fairness Performance Results\"%dataset_used))\n",
    "\n",
    "#Create a new version of the test set with predicted class labels\n",
    "testset_pred = dataset_orig_test.copy()\n",
    "testset_pred.labels = y_test_pred\n",
    "\n",
    "#Construction 1\n",
    "#to construct this metric function, the predicted labels should be united with the test fetures to make a new datas\n",
    "metric_pred_test = BinaryLabelDatasetMetric(testset_pred, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "#Construction 2\n",
    "#both original test dataset with actual labels and the test dataset combined with predicted class labels need to be given to this function\n",
    "classified_metric = ClassificationMetric(dataset_orig_test, \n",
    "                                                 testset_pred,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "\n",
    "\n",
    "#Checking Equalized Odds: average odds differecence, which is the avg. of differences in FPR&TPR for privileged and unprivileged groups.\n",
    "aeo = classified_metric.average_odds_difference()\n",
    "\n",
    "#Disparate Impact ratio between privileged and unprivileged groups.\n",
    "di = classified_metric.disparate_impact()\n",
    "\n",
    "#Demographic parity difference between privileged and unprivileged groups.\n",
    "spd = classified_metric.statistical_parity_difference()\n",
    "\n",
    "#Predictive parity difference: PPV difference between privileged and unprivileged groups.\n",
    "ppd = classified_metric.positive_predictive_value(privileged=False) - classified_metric.positive_predictive_value(privileged=True)\n",
    "\n",
    "#Individual Fairness: 1)Consistency, 2) Euclidean Distance between individuals.\n",
    "consistency = metric_pred_test.consistency()\n",
    "\n",
    "TPR = classified_metric.true_positive_rate() #recall\n",
    "TNR = classified_metric.true_negative_rate() #specificity\n",
    "PPV = classified_metric.positive_predictive_value() #precision\n",
    "bal_acc = (TPR+TNR)/2\n",
    "f1 = 2*((PPV*TPR)/(PPV+TPR))\n",
    "acc = classified_metric.accuracy()\n",
    "\n",
    "ind += [\"Random F imb test set\"]\n",
    "results[\"AEO Difference\"].append(aeo)\n",
    "results[\"Disparate Impact Ratio\"].append(di)\n",
    "results[\"Dem Parity Difference\"].append(spd)\n",
    "results[\"Predictive Parity Difference\"].append(ppd)\n",
    "results[\"Consistency\"].append(consistency)\n",
    "results[\"Accuracy\"].append(acc)\n",
    "results[\"Balanced accuracy\"].append(bal_acc)\n",
    "results[\"F1-Score\"].append(f1)\n",
    "          \n",
    "df_results = pd.DataFrame(results, index=ind)\n",
    "    \n",
    "display(Markdown(\"#### RF Prediction Performance on %s Test Set\"%dataset_used))\n",
    "\n",
    "print(\"For %s dataset\"%dataset_used)\n",
    "print(\"Precision (PPV): %f\" %PPV)\n",
    "print(\"Recall (TPR): %f\" %TPR)\n",
    "print(\"Specificity (TNR): %f\" %TNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AEO Difference</th>\n",
       "      <th>Disparate Impact Ratio</th>\n",
       "      <th>Dem Parity Difference</th>\n",
       "      <th>Predictive Parity Difference</th>\n",
       "      <th>Consistency</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Log reg imb test set</th>\n",
       "      <td>-0.288414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.217140</td>\n",
       "      <td>-0.650163</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.807684</td>\n",
       "      <td>0.667637</td>\n",
       "      <td>0.496965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random F imb test set</th>\n",
       "      <td>-0.317505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.242698</td>\n",
       "      <td>-0.628918</td>\n",
       "      <td>0.999877</td>\n",
       "      <td>0.805910</td>\n",
       "      <td>0.677752</td>\n",
       "      <td>0.514178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       AEO Difference  Disparate Impact Ratio  \\\n",
       "Log reg imb test set        -0.288414                     0.0   \n",
       "Random F imb test set       -0.317505                     0.0   \n",
       "\n",
       "                       Dem Parity Difference  Predictive Parity Difference  \\\n",
       "Log reg imb test set               -0.217140                     -0.650163   \n",
       "Random F imb test set              -0.242698                     -0.628918   \n",
       "\n",
       "                       Consistency  Accuracy  Balanced accuracy  F1-Score  \n",
       "Log reg imb test set      1.000000  0.807684           0.667637  0.496965  \n",
       "Random F imb test set     0.999877  0.805910           0.677752  0.514178  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic regression</th>\n",
       "      <td>0.804042</td>\n",
       "      <td>0.660557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.803284</td>\n",
       "      <td>0.663226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic regression with balanced class weights</th>\n",
       "      <td>0.731993</td>\n",
       "      <td>0.744375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Accuracy  Balanced accuracy\n",
       "Logistic regression                              0.804042           0.660557\n",
       "Random forest                                    0.803284           0.663226\n",
       "Logistic regression with balanced class weights  0.731993           0.744375"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding class weight parameter to logistic regression\n",
    "lr_clf.set_params(logisticregression__class_weight=\"balanced\")\n",
    "\n",
    "index += [\"Logistic regression with balanced class weights\"]\n",
    "cv_result = cross_validate(lr_clf, dataset_X, dataset_y, scoring=scoring)\n",
    "scores[\"Accuracy\"].append(cv_result[\"test_accuracy\"].mean())\n",
    "scores[\"Balanced accuracy\"].append(cv_result[\"test_balanced_accuracy\"].mean())\n",
    "\n",
    "df_scores = pd.DataFrame(scores, index=index)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Weighted LR predictions of adult Test Set: Fairness Performance Results"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass n_neighbors=5 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Weighted LR Prediction Performance on adult Test Set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For adult dataset\n",
      "Precision (PPV): 0.457665\n",
      "Recall (TPR): 0.774632\n",
      "Specificity (TNR): 0.716137\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Training for each dataset\n",
    "log_reg_b = LogisticRegression(class_weight='balanced') \n",
    "\n",
    "#Fitting the training set\n",
    "log_reg_b.fit(X_train, y_train)\n",
    "y_test_pred = log_reg_b.predict(X_test)\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Weighted LR predictions of %s Test Set: Fairness Performance Results\"%dataset_used))\n",
    "\n",
    "#Create a new version of the test set with predicted class labels\n",
    "testset_pred = dataset_orig_test.copy()\n",
    "testset_pred.labels = y_test_pred\n",
    "\n",
    "#Construction 1\n",
    "#to construct this metric function, the predicted labels should be united with the test fetures to make a new datas\n",
    "metric_pred_test = BinaryLabelDatasetMetric(testset_pred, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "#Construction 2\n",
    "#both original test dataset with actual labels and the test dataset combined with predicted class labels need to be given to this function\n",
    "classified_metric = ClassificationMetric(dataset_orig_test, \n",
    "                                                 testset_pred,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "\n",
    "\n",
    "#Checking Equalized Odds: average odds differecence, which is the avg. of differences in FPR&TPR for privileged and unprivileged groups.\n",
    "aeo = classified_metric.average_odds_difference()\n",
    "\n",
    "#Disparate Impact ratio between privileged and unprivileged groups.\n",
    "di = classified_metric.disparate_impact()\n",
    "\n",
    "#Demographic parity difference between privileged and unprivileged groups.\n",
    "spd = classified_metric.statistical_parity_difference()\n",
    "\n",
    "#Predictive parity difference: PPV difference between privileged and unprivileged groups.\n",
    "ppd = classified_metric.positive_predictive_value(privileged=False) - classified_metric.positive_predictive_value(privileged=True)\n",
    "\n",
    "#Individual Fairness: 1)Consistency, 2) Euclidean Distance between individuals.\n",
    "consistency = metric_pred_test.consistency()\n",
    "\n",
    "TPR = classified_metric.true_positive_rate() #recall\n",
    "TNR = classified_metric.true_negative_rate() #specificity\n",
    "PPV = classified_metric.positive_predictive_value() #precision\n",
    "bal_acc = (TPR+TNR)/2\n",
    "f1 = 2*((PPV*TPR)/(PPV+TPR))\n",
    "acc = classified_metric.accuracy()\n",
    "\n",
    "ind += [\"Weighted LR imb test set\"]\n",
    "results[\"AEO Difference\"].append(aeo)\n",
    "results[\"Disparate Impact Ratio\"].append(di)\n",
    "results[\"Dem Parity Difference\"].append(spd)\n",
    "results[\"Predictive Parity Difference\"].append(ppd)\n",
    "results[\"Consistency\"].append(consistency)\n",
    "results[\"Accuracy\"].append(acc)\n",
    "results[\"Balanced accuracy\"].append(bal_acc)\n",
    "results[\"F1-Score\"].append(f1)\n",
    "          \n",
    "df_results = pd.DataFrame(results, index=ind)\n",
    "    \n",
    "display(Markdown(\"#### Weighted LR Prediction Performance on %s Test Set\"%dataset_used))\n",
    "\n",
    "print(\"For %s dataset\"%dataset_used)\n",
    "print(\"Precision (PPV): %f\" %PPV)\n",
    "print(\"Recall (TPR): %f\" %TPR)\n",
    "print(\"Specificity (TNR): %f\" %TNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic regression</th>\n",
       "      <td>0.804042</td>\n",
       "      <td>0.660557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.803284</td>\n",
       "      <td>0.663226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic regression with balanced class weights</th>\n",
       "      <td>0.731993</td>\n",
       "      <td>0.744375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest with balanced class weights</th>\n",
       "      <td>0.728042</td>\n",
       "      <td>0.743390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Accuracy  Balanced accuracy\n",
       "Logistic regression                              0.804042           0.660557\n",
       "Random forest                                    0.803284           0.663226\n",
       "Logistic regression with balanced class weights  0.731993           0.744375\n",
       "Random forest with balanced class weights        0.728042           0.743390"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding class weight parameter to random forest\n",
    "rf_clf.set_params(randomforestclassifier__class_weight=\"balanced\")\n",
    "\n",
    "index += [\"Random forest with balanced class weights\"]\n",
    "cv_result = cross_validate(rf_clf, dataset_X, dataset_y, scoring=scoring)\n",
    "scores[\"Accuracy\"].append(cv_result[\"test_accuracy\"].mean())\n",
    "scores[\"Balanced accuracy\"].append(cv_result[\"test_balanced_accuracy\"].mean())\n",
    "\n",
    "df_scores = pd.DataFrame(scores, index=index)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Weighted RF predictions of adult Test Set: Fairness Performance Results"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass n_neighbors=5 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Weighted RF Prediction Performance on adult Test Set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For adult dataset\n",
      "Precision (PPV): 0.453183\n",
      "Recall (TPR): 0.777521\n",
      "Specificity (TNR): 0.709882\n"
     ]
    }
   ],
   "source": [
    "rfc_b = RandomForestClassifier(random_state=42, n_jobs=2, class_weight='balanced')\n",
    "rfc_b.fit(X_train, y_train)\n",
    "y_test_pred = rfc_b.predict(X_test)\n",
    "\n",
    "display(Markdown(\"#### Weighted RF predictions of %s Test Set: Fairness Performance Results\"%dataset_used))\n",
    "\n",
    "#Create a new version of the test set with predicted class labels\n",
    "testset_pred = dataset_orig_test.copy()\n",
    "testset_pred.labels = y_test_pred\n",
    "\n",
    "#Construction 1\n",
    "#to construct this metric function, the predicted labels should be united with the test fetures to make a new datas\n",
    "metric_pred_test = BinaryLabelDatasetMetric(testset_pred, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "#Construction 2\n",
    "#both original test dataset with actual labels and the test dataset combined with predicted class labels need to be given to this function\n",
    "classified_metric = ClassificationMetric(dataset_orig_test, \n",
    "                                                 testset_pred,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "\n",
    "\n",
    "#Checking Equalized Odds: average odds differecence, which is the avg. of differences in FPR&TPR for privileged and unprivileged groups.\n",
    "aeo = classified_metric.average_odds_difference()\n",
    "\n",
    "#Disparate Impact ratio between privileged and unprivileged groups.\n",
    "di = classified_metric.disparate_impact()\n",
    "\n",
    "#Demographic parity difference between privileged and unprivileged groups.\n",
    "spd = classified_metric.statistical_parity_difference()\n",
    "\n",
    "#Predictive parity difference: PPV difference between privileged and unprivileged groups.\n",
    "ppd = classified_metric.positive_predictive_value(privileged=False) - classified_metric.positive_predictive_value(privileged=True)\n",
    "\n",
    "#Individual Fairness: 1)Consistency, 2) Euclidean Distance between individuals.\n",
    "consistency = metric_pred_test.consistency()\n",
    "\n",
    "TPR = classified_metric.true_positive_rate() #recall\n",
    "TNR = classified_metric.true_negative_rate() #specificity\n",
    "PPV = classified_metric.positive_predictive_value() #precision\n",
    "bal_acc = (TPR+TNR)/2\n",
    "f1 = 2*((PPV*TPR)/(PPV+TPR))\n",
    "acc = classified_metric.accuracy()\n",
    "\n",
    "ind += [\"Weighted RF imb test set\"]\n",
    "results[\"AEO Difference\"].append(aeo)\n",
    "results[\"Disparate Impact Ratio\"].append(di)\n",
    "results[\"Dem Parity Difference\"].append(spd)\n",
    "results[\"Predictive Parity Difference\"].append(ppd)\n",
    "results[\"Consistency\"].append(consistency)\n",
    "results[\"Accuracy\"].append(acc)\n",
    "results[\"Balanced accuracy\"].append(bal_acc)\n",
    "results[\"F1-Score\"].append(f1)\n",
    "          \n",
    "df_results = pd.DataFrame(results, index=ind)\n",
    "    \n",
    "display(Markdown(\"#### Weighted RF Prediction Performance on %s Test Set\"%dataset_used))\n",
    "\n",
    "print(\"For %s dataset\"%dataset_used)\n",
    "print(\"Precision (PPV): %f\" %PPV)\n",
    "print(\"Recall (TPR): %f\" %TPR)\n",
    "print(\"Specificity (TNR): %f\" %TNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AEO Difference</th>\n",
       "      <th>Disparate Impact Ratio</th>\n",
       "      <th>Dem Parity Difference</th>\n",
       "      <th>Predictive Parity Difference</th>\n",
       "      <th>Consistency</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Log reg imb test set</th>\n",
       "      <td>-0.288414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.217140</td>\n",
       "      <td>-0.650163</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.807684</td>\n",
       "      <td>0.667637</td>\n",
       "      <td>0.496965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random F imb test set</th>\n",
       "      <td>-0.317505</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.242698</td>\n",
       "      <td>-0.628918</td>\n",
       "      <td>0.999877</td>\n",
       "      <td>0.805910</td>\n",
       "      <td>0.677752</td>\n",
       "      <td>0.514178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weighted LR imb test set</th>\n",
       "      <td>-0.337787</td>\n",
       "      <td>0.270157</td>\n",
       "      <td>-0.383279</td>\n",
       "      <td>-0.161733</td>\n",
       "      <td>0.999481</td>\n",
       "      <td>0.729953</td>\n",
       "      <td>0.745384</td>\n",
       "      <td>0.575384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weighted RF imb test set</th>\n",
       "      <td>-0.309959</td>\n",
       "      <td>0.302852</td>\n",
       "      <td>-0.365967</td>\n",
       "      <td>-0.169110</td>\n",
       "      <td>0.999563</td>\n",
       "      <td>0.725858</td>\n",
       "      <td>0.743702</td>\n",
       "      <td>0.572614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          AEO Difference  Disparate Impact Ratio  \\\n",
       "Log reg imb test set           -0.288414                0.000000   \n",
       "Random F imb test set          -0.317505                0.000000   \n",
       "Weighted LR imb test set       -0.337787                0.270157   \n",
       "Weighted RF imb test set       -0.309959                0.302852   \n",
       "\n",
       "                          Dem Parity Difference  Predictive Parity Difference  \\\n",
       "Log reg imb test set                  -0.217140                     -0.650163   \n",
       "Random F imb test set                 -0.242698                     -0.628918   \n",
       "Weighted LR imb test set              -0.383279                     -0.161733   \n",
       "Weighted RF imb test set              -0.365967                     -0.169110   \n",
       "\n",
       "                          Consistency  Accuracy  Balanced accuracy  F1-Score  \n",
       "Log reg imb test set         1.000000  0.807684           0.667637  0.496965  \n",
       "Random F imb test set        0.999877  0.805910           0.677752  0.514178  \n",
       "Weighted LR imb test set     0.999481  0.729953           0.745384  0.575384  \n",
       "Weighted RF imb test set     0.999563  0.725858           0.743702  0.572614  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8226\n"
     ]
    }
   ],
   "source": [
    "#It finds that if the dataset has a class imbalance, in terms of positive and negative outcomes.\n",
    "k=0\n",
    "for i in range(len(y_train)):\n",
    "    if(y_train[i] == 1):\n",
    "        k+=1\n",
    "    else:\n",
    "        pass\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0.0 has 25963 instances\n",
      "Class 1.0 has 25965 instances\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cluster_balance_threshold': 0.3,\n",
       " 'density_exponent': 'auto',\n",
       " 'k_neighbors': 2,\n",
       " 'kmeans_estimator': None,\n",
       " 'n_jobs': None,\n",
       " 'random_state': 42,\n",
       " 'sampling_strategy': 'auto'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The oversampling must be done after the dataset is split into train and test sets!\n",
    "#it cannot provide cluster balance with 0.5\n",
    "sm = KMeansSMOTE(k_neighbors=2, random_state=42, cluster_balance_threshold=0.30)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "#Class counts\n",
    "[print('Class {} has {} instances'.format(label, count))\n",
    " for label, count in zip(*np.unique(y_train_res, return_counts=True))]\n",
    "\n",
    "sm.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['race', 'sex', 'Age (decade)=10', 'Age (decade)=20', 'Age (decade)=30',\n",
      "       'Age (decade)=40', 'Age (decade)=50', 'Age (decade)=60',\n",
      "       'Age (decade)=>=70', 'Education Years=6', 'Education Years=7',\n",
      "       'Education Years=8', 'Education Years=9', 'Education Years=10',\n",
      "       'Education Years=11', 'Education Years=12', 'Education Years=<6',\n",
      "       'Education Years=>12', 'labels'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0    0.500019\n",
       "0.0    0.499981\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res_p = pd.DataFrame(X_train_res)\n",
    "\n",
    "X_res_pd = pd.DataFrame(data=X_res_p.values, columns=dataset_orig.feature_names)\n",
    "X_res_pd['labels'] = y_train_res\n",
    "\n",
    "feature_names=X_res_pd.columns\n",
    "print(feature_names)\n",
    "\n",
    "#Check the ratio of class imbalance\n",
    "y_res_p = pd.DataFrame(y_train_res)\n",
    "y_res_p.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'aif360.datasets.structured_dataset.StructuredDataset'>\n",
      "<class 'aif360.datasets.binary_label_dataset.BinaryLabelDataset'>\n",
      "['sex']\n"
     ]
    }
   ],
   "source": [
    "#transform the oversampled training dataset to aif dataset object\n",
    "aif_data = StructuredDataset(df=X_res_pd, label_names=['labels'], protected_attribute_names=['sex'])\n",
    "\n",
    "print(type(aif_data))\n",
    "\n",
    "aif_binary = BinaryLabelDataset(df=X_res_pd, label_names=['labels'], protected_attribute_names=['sex'])\n",
    "print(type(aif_binary))\n",
    "print(aif_binary.protected_attribute_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               instance weights features                                      \\\n",
       "                                         protected attribute                   \n",
       "                                    race                 sex Age (decade)=10   \n",
       "instance names                                                                 \n",
       "0                           1.0      1.0                 1.0             0.0   \n",
       "1                           1.0      1.0                 1.0             0.0   \n",
       "2                           1.0      0.0                 1.0             0.0   \n",
       "3                           1.0      1.0                 1.0             0.0   \n",
       "4                           1.0      1.0                 1.0             0.0   \n",
       "...                         ...      ...                 ...             ...   \n",
       "51923                       1.0      1.0                 1.0             0.0   \n",
       "51924                       1.0      1.0                 1.0             0.0   \n",
       "51925                       1.0      1.0                 0.0             0.0   \n",
       "51926                       1.0      1.0                 0.0             0.0   \n",
       "51927                       1.0      1.0                 0.0             0.0   \n",
       "\n",
       "                                                                \\\n",
       "                                                                 \n",
       "               Age (decade)=20 Age (decade)=30 Age (decade)=40   \n",
       "instance names                                                   \n",
       "0                          0.0             0.0             1.0   \n",
       "1                          1.0             0.0             0.0   \n",
       "2                          0.0             0.0             1.0   \n",
       "3                          0.0             0.0             0.0   \n",
       "4                          1.0             0.0             0.0   \n",
       "...                        ...             ...             ...   \n",
       "51923                      0.0             0.0             0.0   \n",
       "51924                      0.0             0.0             0.0   \n",
       "51925                      0.0             0.0             1.0   \n",
       "51926                      0.0             0.0             1.0   \n",
       "51927                      0.0             1.0             0.0   \n",
       "\n",
       "                                                                  \\\n",
       "                                                                   \n",
       "               Age (decade)=50 Age (decade)=60 Age (decade)=>=70   \n",
       "instance names                                                     \n",
       "0                          0.0             0.0               0.0   \n",
       "1                          0.0             0.0               0.0   \n",
       "2                          0.0             0.0               0.0   \n",
       "3                          1.0             0.0               0.0   \n",
       "4                          0.0             0.0               0.0   \n",
       "...                        ...             ...               ...   \n",
       "51923                      1.0             0.0               0.0   \n",
       "51924                      1.0             0.0               0.0   \n",
       "51925                      0.0             0.0               0.0   \n",
       "51926                      0.0             0.0               0.0   \n",
       "51927                      0.0             0.0               0.0   \n",
       "\n",
       "                                                                      \\\n",
       "                                                                       \n",
       "               Education Years=6 Education Years=7 Education Years=8   \n",
       "instance names                                                         \n",
       "0                            0.0               0.0               0.0   \n",
       "1                            0.0               0.0               0.0   \n",
       "2                            0.0               0.0               0.0   \n",
       "3                            0.0               0.0               0.0   \n",
       "4                            0.0               0.0               0.0   \n",
       "...                          ...               ...               ...   \n",
       "51923                        0.0               0.0               0.0   \n",
       "51924                        0.0               0.0               0.0   \n",
       "51925                        0.0               0.0               0.0   \n",
       "51926                        0.0               0.0               0.0   \n",
       "51927                        0.0               0.0               0.0   \n",
       "\n",
       "                                                                        \\\n",
       "                                                                         \n",
       "               Education Years=9 Education Years=10 Education Years=11   \n",
       "instance names                                                           \n",
       "0                            0.0                0.0                0.0   \n",
       "1                            0.0                1.0                0.0   \n",
       "2                            0.0                1.0                0.0   \n",
       "3                            1.0                0.0                0.0   \n",
       "4                            0.0                0.0                0.0   \n",
       "...                          ...                ...                ...   \n",
       "51923                        0.0                0.0                0.0   \n",
       "51924                        0.0                0.0                0.0   \n",
       "51925                        0.0                0.0                0.0   \n",
       "51926                        0.0                0.0                0.0   \n",
       "51927                        0.0                0.0                0.0   \n",
       "\n",
       "                                                                          \\\n",
       "                                                                           \n",
       "               Education Years=12 Education Years=<6 Education Years=>12   \n",
       "instance names                                                             \n",
       "0                             0.0                0.0                 1.0   \n",
       "1                             0.0                0.0                 0.0   \n",
       "2                             0.0                0.0                 0.0   \n",
       "3                             0.0                0.0                 0.0   \n",
       "4                             1.0                0.0                 0.0   \n",
       "...                           ...                ...                 ...   \n",
       "51923                         0.0                0.0                 1.0   \n",
       "51924                         0.0                0.0                 1.0   \n",
       "51925                         0.0                0.0                 1.0   \n",
       "51926                         0.0                0.0                 1.0   \n",
       "51927                         0.0                0.0                 1.0   \n",
       "\n",
       "               labels  \n",
       "                       \n",
       "                       \n",
       "instance names         \n",
       "0                 1.0  \n",
       "1                 0.0  \n",
       "2                 1.0  \n",
       "3                 0.0  \n",
       "4                 0.0  \n",
       "...               ...  \n",
       "51923             1.0  \n",
       "51924             1.0  \n",
       "51925             1.0  \n",
       "51926             1.0  \n",
       "51927             1.0  \n",
       "\n",
       "[51928 rows x 20 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aif_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Transformed adult train set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate impact ratio (of transformed labels) between unprivileged and privileged groups = 0.810589\n",
      "Difference in statistical parity (of transformed labels) between unprivileged and privileged groups = -0.101305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass n_neighbors=5 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual fairness metric 'consistency' that measures how similar the labels are for similar instances = 0.697254\n"
     ]
    }
   ],
   "source": [
    "# Initial disparities in the oversampled datasets\n",
    "\n",
    "metric_transf = BinaryLabelDatasetMetric(aif_binary, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "display(Markdown(\"#### Transformed %s train set\"%dataset_used))\n",
    "print(\"Disparate impact ratio (of transformed labels) between unprivileged and privileged groups = %f\" % metric_transf.disparate_impact())\n",
    "print(\"Difference in statistical parity (of transformed labels) between unprivileged and privileged groups = %f\" % metric_transf.statistical_parity_difference())\n",
    "print(\"Individual fairness metric 'consistency' that measures how similar the labels are for similar instances = %f\" % metric_transf.consistency())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the oversampled dataset with logistic regression\n",
    "X_transf_train = aif_binary.features\n",
    "y_transf_train = aif_binary.labels.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### LR predictions of adult Test Set: Fairness Performance Results"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass n_neighbors=5 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### LR Prediction Performance on adult Test Set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For adult dataset\n",
      "Precision (PPV): 0.553329\n",
      "Recall (TPR): 0.518636\n",
      "Specificity (TNR): 0.870533\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Training for each dataset\n",
    "log_reg_t = LogisticRegression() \n",
    "\n",
    "#Fitting the training set\n",
    "log_reg_t.fit(X_transf_train, y_transf_train)\n",
    "y_transf_test_pred = log_reg_t.predict(X_test)\n",
    "\n",
    "display(Markdown(\"#### LR predictions of %s Test Set: Fairness Performance Results\"%dataset_used))\n",
    "\n",
    "#Create a new version of the test set with predicted class labels\n",
    "testset_transf_pred = dataset_orig_test.copy()\n",
    "testset_transf_pred.labels = y_transf_test_pred\n",
    "\n",
    "#Construction 1\n",
    "#to construct this metric function, the predicted labels should be united with the test fetures to make a new datas\n",
    "metric_pred_test = BinaryLabelDatasetMetric(testset_transf_pred, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "#Construction 2\n",
    "#both original test dataset with actual labels and the test dataset combined with predicted class labels need to be given to this function\n",
    "classified_metric = ClassificationMetric(dataset_orig_test, \n",
    "                                                 testset_transf_pred,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "\n",
    "\n",
    "#Checking Equalized Odds: average odds differecence, which is the avg. of differences in FPR&TPR for privileged and unprivileged groups.\n",
    "aeo = classified_metric.average_odds_difference()\n",
    "\n",
    "#Disparate Impact ratio between privileged and unprivileged groups.\n",
    "di = classified_metric.disparate_impact()\n",
    "\n",
    "#Demographic parity difference between privileged and unprivileged groups.\n",
    "spd = classified_metric.statistical_parity_difference()\n",
    "\n",
    "#Predictive parity difference: PPV difference between privileged and unprivileged groups.\n",
    "ppd = classified_metric.positive_predictive_value(privileged=False) - classified_metric.positive_predictive_value(privileged=True)\n",
    "\n",
    "#Individual Fairness: 1)Consistency, 2) Euclidean Distance between individuals.\n",
    "consistency = metric_pred_test.consistency()\n",
    "\n",
    "TPR = classified_metric.true_positive_rate() #recall\n",
    "TNR = classified_metric.true_negative_rate() #specificity\n",
    "PPV = classified_metric.positive_predictive_value() #precision\n",
    "bal_acc = (TPR+TNR)/2\n",
    "f1 = 2*((PPV*TPR)/(PPV+TPR))\n",
    "acc = classified_metric.accuracy()\n",
    "\n",
    "ind += [\"Log reg (oversampled) test set\"]\n",
    "results[\"AEO Difference\"].append(aeo)\n",
    "results[\"Disparate Impact Ratio\"].append(di)\n",
    "results[\"Dem Parity Difference\"].append(spd)\n",
    "results[\"Predictive Parity Difference\"].append(ppd)\n",
    "results[\"Consistency\"].append(consistency)\n",
    "results[\"Accuracy\"].append(acc)\n",
    "results[\"Balanced accuracy\"].append(bal_acc)\n",
    "results[\"F1-Score\"].append(f1)\n",
    "          \n",
    "df_results = pd.DataFrame(results, index=ind)\n",
    "    \n",
    "display(Markdown(\"#### LR Prediction Performance on %s Test Set\"%dataset_used))\n",
    "\n",
    "print(\"For %s dataset\"%dataset_used)\n",
    "print(\"Precision (PPV): %f\" %PPV)\n",
    "print(\"Recall (TPR): %f\" %TPR)\n",
    "print(\"Specificity (TNR): %f\" %TNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### RFC predictions of adult Test Set: Fairness Performance Results"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass n_neighbors=5 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### RF Prediction Performance on adult Test Set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For adult dataset\n",
      "Precision (PPV): 0.551077\n",
      "Recall (TPR): 0.517480\n",
      "Specificity (TNR): 0.869639\n"
     ]
    }
   ],
   "source": [
    "#Training the oversampled dataset with random forestrfc_t = RandomForestClassifier(random_state=42, n_jobs=2)\n",
    "rfc_t.fit(X_transf_train, y_transf_train)\n",
    "y_test_transf_pred = rfc_t.predict(X_test)\n",
    "\n",
    "display(Markdown(\"#### RFC predictions of %s Test Set: Fairness Performance Results\"%dataset_used))\n",
    "\n",
    "#Create a new version of the test set with predicted class labels\n",
    "testset_transf_pred = dataset_orig_test.copy()\n",
    "testset_transf_pred.labels = y_test_transf_pred\n",
    "\n",
    "#Construction 1\n",
    "#to construct this metric function, the predicted labels should be united with the test fetures to make a new datas\n",
    "metric_pred_test = BinaryLabelDatasetMetric(testset_transf_pred, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "#Construction 2\n",
    "#both original test dataset with actual labels and the test dataset combined with predicted class labels need to be given to this function\n",
    "classified_metric = ClassificationMetric(dataset_orig_test, \n",
    "                                                 testset_transf_pred,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "\n",
    "\n",
    "#Checking Equalized Odds: average odds differecence, which is the avg. of differences in FPR&TPR for privileged and unprivileged groups.\n",
    "aeo = classified_metric.average_odds_difference()\n",
    "\n",
    "#Disparate Impact ratio between privileged and unprivileged groups.\n",
    "di = classified_metric.disparate_impact()\n",
    "\n",
    "#Demographic parity difference between privileged and unprivileged groups.\n",
    "spd = classified_metric.statistical_parity_difference()\n",
    "\n",
    "#Predictive parity difference: PPV difference between privileged and unprivileged groups.\n",
    "ppd = classified_metric.positive_predictive_value(privileged=False) - classified_metric.positive_predictive_value(privileged=True)\n",
    "\n",
    "#Individual Fairness: 1)Consistency, 2) Euclidean Distance between individuals.\n",
    "consistency = metric_pred_test.consistency()\n",
    "\n",
    "TPR = classified_metric.true_positive_rate() #recall\n",
    "TNR = classified_metric.true_negative_rate() #specificity\n",
    "PPV = classified_metric.positive_predictive_value() #precision\n",
    "bal_acc = (TPR+TNR)/2\n",
    "f1 = 2*((PPV*TPR)/(PPV+TPR))\n",
    "acc = classified_metric.accuracy()\n",
    "\n",
    "ind += [\"Random F (oversampled) test set\"]\n",
    "results[\"AEO Difference\"].append(aeo)\n",
    "results[\"Disparate Impact Ratio\"].append(di)\n",
    "results[\"Dem Parity Difference\"].append(spd)\n",
    "results[\"Predictive Parity Difference\"].append(ppd)\n",
    "results[\"Consistency\"].append(consistency)\n",
    "results[\"Accuracy\"].append(acc)\n",
    "results[\"Balanced accuracy\"].append(bal_acc)\n",
    "results[\"F1-Score\"].append(f1)\n",
    "          \n",
    "df_results = pd.DataFrame(results, index=ind)\n",
    "    \n",
    "display(Markdown(\"#### RF Prediction Performance on %s Test Set\"%dataset_used))\n",
    "\n",
    "print(\"For %s dataset\"%dataset_used)\n",
    "print(\"Precision (PPV): %f\" %PPV)\n",
    "print(\"Recall (TPR): %f\" %TPR)\n",
    "print(\"Specificity (TNR): %f\" %TNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AEO Difference</th>\n",
       "      <th>Disparate Impact Ratio</th>\n",
       "      <th>Dem Parity Difference</th>\n",
       "      <th>Predictive Parity Difference</th>\n",
       "      <th>Consistency</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Log reg imb test set</th>\n",
       "      <td>-0.288414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.217140</td>\n",
       "      <td>-0.650163</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.807684</td>\n",
       "      <td>0.667637</td>\n",
       "      <td>0.496965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random F imb test set</th>\n",
       "      <td>-0.317505</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.242698</td>\n",
       "      <td>-0.628918</td>\n",
       "      <td>0.999877</td>\n",
       "      <td>0.805910</td>\n",
       "      <td>0.677752</td>\n",
       "      <td>0.514178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weighted LR imb test set</th>\n",
       "      <td>-0.337787</td>\n",
       "      <td>0.270157</td>\n",
       "      <td>-0.383279</td>\n",
       "      <td>-0.161733</td>\n",
       "      <td>0.999481</td>\n",
       "      <td>0.729953</td>\n",
       "      <td>0.745384</td>\n",
       "      <td>0.575384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weighted RF imb test set</th>\n",
       "      <td>-0.309959</td>\n",
       "      <td>0.302852</td>\n",
       "      <td>-0.365967</td>\n",
       "      <td>-0.169110</td>\n",
       "      <td>0.999563</td>\n",
       "      <td>0.725858</td>\n",
       "      <td>0.743702</td>\n",
       "      <td>0.572614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log reg (oversampled) test set</th>\n",
       "      <td>-0.040338</td>\n",
       "      <td>0.605822</td>\n",
       "      <td>-0.100184</td>\n",
       "      <td>-0.319864</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.787416</td>\n",
       "      <td>0.694584</td>\n",
       "      <td>0.535421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random F (oversampled) test set</th>\n",
       "      <td>-0.040392</td>\n",
       "      <td>0.604375</td>\n",
       "      <td>-0.100792</td>\n",
       "      <td>-0.316776</td>\n",
       "      <td>0.999864</td>\n",
       "      <td>0.786460</td>\n",
       "      <td>0.693560</td>\n",
       "      <td>0.533751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 AEO Difference  Disparate Impact Ratio  \\\n",
       "Log reg imb test set                  -0.288414                0.000000   \n",
       "Random F imb test set                 -0.317505                0.000000   \n",
       "Weighted LR imb test set              -0.337787                0.270157   \n",
       "Weighted RF imb test set              -0.309959                0.302852   \n",
       "Log reg (oversampled) test set        -0.040338                0.605822   \n",
       "Random F (oversampled) test set       -0.040392                0.604375   \n",
       "\n",
       "                                 Dem Parity Difference  \\\n",
       "Log reg imb test set                         -0.217140   \n",
       "Random F imb test set                        -0.242698   \n",
       "Weighted LR imb test set                     -0.383279   \n",
       "Weighted RF imb test set                     -0.365967   \n",
       "Log reg (oversampled) test set               -0.100184   \n",
       "Random F (oversampled) test set              -0.100792   \n",
       "\n",
       "                                 Predictive Parity Difference  Consistency  \\\n",
       "Log reg imb test set                                -0.650163     1.000000   \n",
       "Random F imb test set                               -0.628918     0.999877   \n",
       "Weighted LR imb test set                            -0.161733     0.999481   \n",
       "Weighted RF imb test set                            -0.169110     0.999563   \n",
       "Log reg (oversampled) test set                      -0.319864     0.999959   \n",
       "Random F (oversampled) test set                     -0.316776     0.999864   \n",
       "\n",
       "                                 Accuracy  Balanced accuracy  F1-Score  \n",
       "Log reg imb test set             0.807684           0.667637  0.496965  \n",
       "Random F imb test set            0.805910           0.677752  0.514178  \n",
       "Weighted LR imb test set         0.729953           0.745384  0.575384  \n",
       "Weighted RF imb test set         0.725858           0.743702  0.572614  \n",
       "Log reg (oversampled) test set   0.787416           0.694584  0.535421  \n",
       "Random F (oversampled) test set  0.786460           0.693560  0.533751  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aif360",
   "language": "python",
   "name": "aif360"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

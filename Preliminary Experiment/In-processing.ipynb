{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Experiments with Existing Algorithms Part 2: In-Processing algorithm- Adversarial Debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets import AdultDataset, GermanDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult, load_preproc_data_german\n",
    "\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "import random\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the datasets\n",
    "\n",
    "#Adult\n",
    "adult_orig = load_preproc_data_adult()\n",
    "\n",
    "a_privileged_groups = [{'sex': 1}]\n",
    "a_unprivileged_groups = [{'sex': 0}]\n",
    "\n",
    "adult_orig_train, adult_orig_test = adult_orig.split([0.7], shuffle=True)\n",
    "\n",
    "#German\n",
    "german_orig = load_preproc_data_german()\n",
    "\n",
    "for i in range(1000):\n",
    "    if (german_orig.labels[i] == 2.0):\n",
    "        german_orig.labels[i] = 0\n",
    "    else:\n",
    "        german_orig.labels[i] = 1\n",
    "        \n",
    "german_orig.favorable_label = 1\n",
    "german_orig.unfavorable_label = 0\n",
    "\n",
    "g_privileged_groups = [{'age': 1}]\n",
    "g_unprivileged_groups = [{'age': 0}]\n",
    "\n",
    "german_orig_train, german_orig_test = german_orig.split([0.7], shuffle=True)\n",
    "\n",
    "#Scaling the datasets\n",
    "std_scaler = StandardScaler()\n",
    "\n",
    "#Adult\n",
    "adult_orig_train.features = std_scaler.fit_transform(adult_orig_train.features)\n",
    "adult_orig_test.features = std_scaler.transform(adult_orig_test.features)\n",
    "\n",
    "#German\n",
    "german_orig_train.features = std_scaler.fit_transform(german_orig_train.features)\n",
    "german_orig_test.features = std_scaler.transform(german_orig_test.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:137: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:141: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:84: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:89: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:159: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:161: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:165: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:187: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\hatta\\anaconda3\\envs\\aif360\\lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:188: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702637; batch adversarial loss: 0.643104\n",
      "epoch 0; iter: 200; batch classifier loss: 0.446043; batch adversarial loss: 0.632510\n",
      "epoch 1; iter: 0; batch classifier loss: 0.449528; batch adversarial loss: 0.631461\n",
      "epoch 1; iter: 200; batch classifier loss: 0.565505; batch adversarial loss: 0.593458\n",
      "epoch 2; iter: 0; batch classifier loss: 0.463715; batch adversarial loss: 0.627835\n",
      "epoch 2; iter: 200; batch classifier loss: 0.480556; batch adversarial loss: 0.637914\n",
      "epoch 3; iter: 0; batch classifier loss: 0.468187; batch adversarial loss: 0.598563\n",
      "epoch 3; iter: 200; batch classifier loss: 0.485439; batch adversarial loss: 0.625070\n",
      "epoch 4; iter: 0; batch classifier loss: 0.425566; batch adversarial loss: 0.559488\n",
      "epoch 4; iter: 200; batch classifier loss: 0.497857; batch adversarial loss: 0.608611\n",
      "epoch 5; iter: 0; batch classifier loss: 0.520671; batch adversarial loss: 0.596411\n",
      "epoch 5; iter: 200; batch classifier loss: 0.432794; batch adversarial loss: 0.588477\n",
      "epoch 6; iter: 0; batch classifier loss: 0.385044; batch adversarial loss: 0.591188\n",
      "epoch 6; iter: 200; batch classifier loss: 0.493745; batch adversarial loss: 0.618763\n",
      "epoch 7; iter: 0; batch classifier loss: 0.456887; batch adversarial loss: 0.595009\n",
      "epoch 7; iter: 200; batch classifier loss: 0.480604; batch adversarial loss: 0.615613\n",
      "epoch 8; iter: 0; batch classifier loss: 0.409577; batch adversarial loss: 0.600578\n",
      "epoch 8; iter: 200; batch classifier loss: 0.543765; batch adversarial loss: 0.584667\n",
      "epoch 9; iter: 0; batch classifier loss: 0.473540; batch adversarial loss: 0.596981\n",
      "epoch 9; iter: 200; batch classifier loss: 0.407816; batch adversarial loss: 0.643017\n",
      "epoch 10; iter: 0; batch classifier loss: 0.455599; batch adversarial loss: 0.572640\n",
      "epoch 10; iter: 200; batch classifier loss: 0.403434; batch adversarial loss: 0.639807\n",
      "epoch 11; iter: 0; batch classifier loss: 0.476783; batch adversarial loss: 0.617575\n",
      "epoch 11; iter: 200; batch classifier loss: 0.435772; batch adversarial loss: 0.636393\n",
      "epoch 12; iter: 0; batch classifier loss: 0.419219; batch adversarial loss: 0.585610\n",
      "epoch 12; iter: 200; batch classifier loss: 0.381363; batch adversarial loss: 0.626385\n",
      "epoch 13; iter: 0; batch classifier loss: 0.453920; batch adversarial loss: 0.591970\n",
      "epoch 13; iter: 200; batch classifier loss: 0.439005; batch adversarial loss: 0.625667\n",
      "epoch 14; iter: 0; batch classifier loss: 0.472969; batch adversarial loss: 0.572030\n",
      "epoch 14; iter: 200; batch classifier loss: 0.571285; batch adversarial loss: 0.602795\n",
      "epoch 15; iter: 0; batch classifier loss: 0.556355; batch adversarial loss: 0.627983\n",
      "epoch 15; iter: 200; batch classifier loss: 0.439406; batch adversarial loss: 0.609141\n",
      "epoch 16; iter: 0; batch classifier loss: 0.411538; batch adversarial loss: 0.624747\n",
      "epoch 16; iter: 200; batch classifier loss: 0.379637; batch adversarial loss: 0.616126\n",
      "epoch 17; iter: 0; batch classifier loss: 0.394668; batch adversarial loss: 0.641421\n",
      "epoch 17; iter: 200; batch classifier loss: 0.465816; batch adversarial loss: 0.650304\n",
      "epoch 18; iter: 0; batch classifier loss: 0.474180; batch adversarial loss: 0.636991\n",
      "epoch 18; iter: 200; batch classifier loss: 0.378783; batch adversarial loss: 0.610576\n",
      "epoch 19; iter: 0; batch classifier loss: 0.510188; batch adversarial loss: 0.593124\n",
      "epoch 19; iter: 200; batch classifier loss: 0.433693; batch adversarial loss: 0.625736\n",
      "epoch 20; iter: 0; batch classifier loss: 0.423834; batch adversarial loss: 0.603149\n",
      "epoch 20; iter: 200; batch classifier loss: 0.434819; batch adversarial loss: 0.604131\n",
      "epoch 21; iter: 0; batch classifier loss: 0.481800; batch adversarial loss: 0.622242\n",
      "epoch 21; iter: 200; batch classifier loss: 0.499771; batch adversarial loss: 0.612289\n",
      "epoch 22; iter: 0; batch classifier loss: 0.475720; batch adversarial loss: 0.584612\n",
      "epoch 22; iter: 200; batch classifier loss: 0.452298; batch adversarial loss: 0.590906\n",
      "epoch 23; iter: 0; batch classifier loss: 0.381792; batch adversarial loss: 0.634188\n",
      "epoch 23; iter: 200; batch classifier loss: 0.494642; batch adversarial loss: 0.612154\n",
      "epoch 24; iter: 0; batch classifier loss: 0.363037; batch adversarial loss: 0.608994\n",
      "epoch 24; iter: 200; batch classifier loss: 0.466827; batch adversarial loss: 0.629512\n",
      "epoch 25; iter: 0; batch classifier loss: 0.394404; batch adversarial loss: 0.619183\n",
      "epoch 25; iter: 200; batch classifier loss: 0.513718; batch adversarial loss: 0.646980\n",
      "epoch 26; iter: 0; batch classifier loss: 0.389931; batch adversarial loss: 0.580637\n",
      "epoch 26; iter: 200; batch classifier loss: 0.362207; batch adversarial loss: 0.581990\n",
      "epoch 27; iter: 0; batch classifier loss: 0.387135; batch adversarial loss: 0.585649\n",
      "epoch 27; iter: 200; batch classifier loss: 0.527813; batch adversarial loss: 0.564877\n",
      "epoch 28; iter: 0; batch classifier loss: 0.395442; batch adversarial loss: 0.562184\n",
      "epoch 28; iter: 200; batch classifier loss: 0.398720; batch adversarial loss: 0.603665\n",
      "epoch 29; iter: 0; batch classifier loss: 0.410731; batch adversarial loss: 0.615739\n",
      "epoch 29; iter: 200; batch classifier loss: 0.347121; batch adversarial loss: 0.671578\n",
      "epoch 30; iter: 0; batch classifier loss: 0.444418; batch adversarial loss: 0.679635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 200; batch classifier loss: 0.483944; batch adversarial loss: 0.657298\n",
      "epoch 31; iter: 0; batch classifier loss: 0.448528; batch adversarial loss: 0.589990\n",
      "epoch 31; iter: 200; batch classifier loss: 0.435900; batch adversarial loss: 0.643269\n",
      "epoch 32; iter: 0; batch classifier loss: 0.508764; batch adversarial loss: 0.629034\n",
      "epoch 32; iter: 200; batch classifier loss: 0.320070; batch adversarial loss: 0.614476\n",
      "epoch 33; iter: 0; batch classifier loss: 0.455155; batch adversarial loss: 0.630397\n",
      "epoch 33; iter: 200; batch classifier loss: 0.397175; batch adversarial loss: 0.599331\n",
      "epoch 34; iter: 0; batch classifier loss: 0.433399; batch adversarial loss: 0.605128\n",
      "epoch 34; iter: 200; batch classifier loss: 0.380709; batch adversarial loss: 0.571620\n",
      "epoch 35; iter: 0; batch classifier loss: 0.424173; batch adversarial loss: 0.567642\n",
      "epoch 35; iter: 200; batch classifier loss: 0.473366; batch adversarial loss: 0.597303\n",
      "epoch 36; iter: 0; batch classifier loss: 0.333765; batch adversarial loss: 0.610856\n",
      "epoch 36; iter: 200; batch classifier loss: 0.504115; batch adversarial loss: 0.524601\n",
      "epoch 37; iter: 0; batch classifier loss: 0.479863; batch adversarial loss: 0.629958\n",
      "epoch 37; iter: 200; batch classifier loss: 0.470176; batch adversarial loss: 0.605557\n",
      "epoch 38; iter: 0; batch classifier loss: 0.460808; batch adversarial loss: 0.605980\n",
      "epoch 38; iter: 200; batch classifier loss: 0.441620; batch adversarial loss: 0.603004\n",
      "epoch 39; iter: 0; batch classifier loss: 0.480842; batch adversarial loss: 0.596660\n",
      "epoch 39; iter: 200; batch classifier loss: 0.446379; batch adversarial loss: 0.600558\n",
      "epoch 40; iter: 0; batch classifier loss: 0.436479; batch adversarial loss: 0.667086\n",
      "epoch 40; iter: 200; batch classifier loss: 0.351720; batch adversarial loss: 0.619715\n",
      "epoch 41; iter: 0; batch classifier loss: 0.447754; batch adversarial loss: 0.587338\n",
      "epoch 41; iter: 200; batch classifier loss: 0.545910; batch adversarial loss: 0.621855\n",
      "epoch 42; iter: 0; batch classifier loss: 0.339407; batch adversarial loss: 0.648622\n",
      "epoch 42; iter: 200; batch classifier loss: 0.434302; batch adversarial loss: 0.573869\n",
      "epoch 43; iter: 0; batch classifier loss: 0.316647; batch adversarial loss: 0.570659\n",
      "epoch 43; iter: 200; batch classifier loss: 0.482433; batch adversarial loss: 0.588754\n",
      "epoch 44; iter: 0; batch classifier loss: 0.431610; batch adversarial loss: 0.626809\n",
      "epoch 44; iter: 200; batch classifier loss: 0.408103; batch adversarial loss: 0.637263\n",
      "epoch 45; iter: 0; batch classifier loss: 0.403977; batch adversarial loss: 0.593193\n",
      "epoch 45; iter: 200; batch classifier loss: 0.524477; batch adversarial loss: 0.583324\n",
      "epoch 46; iter: 0; batch classifier loss: 0.408116; batch adversarial loss: 0.630082\n",
      "epoch 46; iter: 200; batch classifier loss: 0.583442; batch adversarial loss: 0.645747\n",
      "epoch 47; iter: 0; batch classifier loss: 0.406462; batch adversarial loss: 0.603723\n",
      "epoch 47; iter: 200; batch classifier loss: 0.345456; batch adversarial loss: 0.623322\n",
      "epoch 48; iter: 0; batch classifier loss: 0.485539; batch adversarial loss: 0.551453\n",
      "epoch 48; iter: 200; batch classifier loss: 0.469378; batch adversarial loss: 0.564169\n",
      "epoch 49; iter: 0; batch classifier loss: 0.381509; batch adversarial loss: 0.571329\n",
      "epoch 49; iter: 200; batch classifier loss: 0.497403; batch adversarial loss: 0.605199\n"
     ]
    }
   ],
   "source": [
    "#start a tesnforflow session for Adversarial Debiasing\n",
    "sess = tf.Session()\n",
    "\n",
    "# Learn parameters with debias set to True\n",
    "#Debiasing Model for Adult dataset\n",
    "\n",
    "adult_model = AdversarialDebiasing(privileged_groups = a_privileged_groups,\n",
    "                          unprivileged_groups = a_unprivileged_groups,\n",
    "                          scope_name='debiased_adult_classifier',\n",
    "                          debias=True,\n",
    "                          sess=sess)\n",
    "\n",
    "adult_model.fit(adult_orig_train)\n",
    "\n",
    "#pred_debiased_train_a = adult_model.predict(adult_orig_train)\n",
    "pred_debiased_test_a = adult_model.predict(adult_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               instance weights            features                       \\\n",
       "                                protected attribute                        \n",
       "                                               race  sex Age (decade)=10   \n",
       "instance names                                                             \n",
       "6745                        1.0                 1.0  1.0       -0.230934   \n",
       "40581                       1.0                 1.0  1.0       -0.230934   \n",
       "33909                       1.0                 0.0  1.0       -0.230934   \n",
       "20134                       1.0                 1.0  1.0       -0.230934   \n",
       "6724                        1.0                 1.0  1.0       -0.230934   \n",
       "...                         ...                 ...  ...             ...   \n",
       "4350                        1.0                 1.0  0.0       -0.230934   \n",
       "42342                       1.0                 1.0  1.0       -0.230934   \n",
       "2981                        1.0                 1.0  1.0       -0.230934   \n",
       "18369                       1.0                 1.0  0.0       -0.230934   \n",
       "14295                       1.0                 1.0  1.0       -0.230934   \n",
       "\n",
       "                                                                \\\n",
       "                                                                 \n",
       "               Age (decade)=20 Age (decade)=30 Age (decade)=40   \n",
       "instance names                                                   \n",
       "6745                 -0.570449       -0.603020        1.886085   \n",
       "40581                -0.570449       -0.603020        1.886085   \n",
       "33909                -0.570449       -0.603020       -0.530199   \n",
       "20134                 1.753006       -0.603020       -0.530199   \n",
       "6724                 -0.570449       -0.603020       -0.530199   \n",
       "...                        ...             ...             ...   \n",
       "4350                 -0.570449       -0.603020       -0.530199   \n",
       "42342                 1.753006       -0.603020       -0.530199   \n",
       "2981                  1.753006       -0.603020       -0.530199   \n",
       "18369                -0.570449        1.658321       -0.530199   \n",
       "14295                 1.753006       -0.603020       -0.530199   \n",
       "\n",
       "                                                                  \\\n",
       "                                                                   \n",
       "               Age (decade)=50 Age (decade)=60 Age (decade)=>=70   \n",
       "instance names                                                     \n",
       "6745                 -0.395179       -0.258404           -0.1432   \n",
       "40581                -0.395179       -0.258404           -0.1432   \n",
       "33909                 2.530498       -0.258404           -0.1432   \n",
       "20134                -0.395179       -0.258404           -0.1432   \n",
       "6724                  2.530498       -0.258404           -0.1432   \n",
       "...                        ...             ...               ...   \n",
       "4350                  2.530498       -0.258404           -0.1432   \n",
       "42342                -0.395179       -0.258404           -0.1432   \n",
       "2981                 -0.395179       -0.258404           -0.1432   \n",
       "18369                -0.395179       -0.258404           -0.1432   \n",
       "14295                -0.395179       -0.258404           -0.1432   \n",
       "\n",
       "                                                                      \\\n",
       "                                                                       \n",
       "               Education Years=6 Education Years=7 Education Years=8   \n",
       "instance names                                                         \n",
       "6745                   -0.172055          5.037897         -0.116911   \n",
       "40581                  -0.172055         -0.198496         -0.116911   \n",
       "33909                  -0.172055          5.037897         -0.116911   \n",
       "20134                  -0.172055         -0.198496          8.553519   \n",
       "6724                   -0.172055         -0.198496         -0.116911   \n",
       "...                          ...               ...               ...   \n",
       "4350                   -0.172055         -0.198496         -0.116911   \n",
       "42342                  -0.172055         -0.198496          8.553519   \n",
       "2981                   -0.172055         -0.198496         -0.116911   \n",
       "18369                  -0.172055         -0.198496         -0.116911   \n",
       "14295                  -0.172055         -0.198496         -0.116911   \n",
       "\n",
       "                                                                        \\\n",
       "                                                                         \n",
       "               Education Years=9 Education Years=10 Education Years=11   \n",
       "instance names                                                           \n",
       "6745                   -0.688786          -0.534316          -0.210375   \n",
       "40581                  -0.688786          -0.534316           4.753409   \n",
       "33909                  -0.688786          -0.534316          -0.210375   \n",
       "20134                  -0.688786          -0.534316          -0.210375   \n",
       "6724                    1.451829          -0.534316          -0.210375   \n",
       "...                          ...                ...                ...   \n",
       "4350                   -0.688786          -0.534316          -0.210375   \n",
       "42342                  -0.688786          -0.534316          -0.210375   \n",
       "2981                   -0.688786           1.871550          -0.210375   \n",
       "18369                   1.451829          -0.534316          -0.210375   \n",
       "14295                   1.451829          -0.534316          -0.210375   \n",
       "\n",
       "                                                                          \\\n",
       "                                                                           \n",
       "               Education Years=12 Education Years=<6 Education Years=>12   \n",
       "instance names                                                             \n",
       "6745                    -0.184034           -0.23387           -0.575808   \n",
       "40581                   -0.184034           -0.23387           -0.575808   \n",
       "33909                   -0.184034           -0.23387           -0.575808   \n",
       "20134                   -0.184034           -0.23387           -0.575808   \n",
       "6724                    -0.184034           -0.23387           -0.575808   \n",
       "...                           ...                ...                 ...   \n",
       "4350                     5.433773           -0.23387           -0.575808   \n",
       "42342                   -0.184034           -0.23387           -0.575808   \n",
       "2981                    -0.184034           -0.23387           -0.575808   \n",
       "18369                   -0.184034           -0.23387           -0.575808   \n",
       "14295                   -0.184034           -0.23387           -0.575808   \n",
       "\n",
       "               labels  \n",
       "                       \n",
       "                       \n",
       "instance names         \n",
       "6745              0.0  \n",
       "40581             0.0  \n",
       "33909             0.0  \n",
       "20134             0.0  \n",
       "6724              0.0  \n",
       "...               ...  \n",
       "4350              0.0  \n",
       "42342             0.0  \n",
       "2981              0.0  \n",
       "18369             0.0  \n",
       "14295             0.0  \n",
       "\n",
       "[14653 rows x 20 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_debiased_test_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Debiased LR with Adult Test Set Fairness Performance (based on predictions)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average equalized odds difference between unprivileged and privileged groups = -0.016155\n",
      "Disparate impact ratio between unprivileged and privileged groups = 0.632561\n",
      "Demographic parity difference between unprivileged and privileged groups = -0.073772\n",
      "Predictive Parity difference between unprivileged and privileged groups = -0.298572\n",
      "Consistency of indivuals' predicted labels = 1.000000\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Debiased LR with Adult Test Set Prediction Performance"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard accuracy of logistic regression trained on German dataset without any mitigation = 0.791715\n",
      "Balanced accuracy of logistic regression trained on German dataset without any mitigation = 0.668590\n",
      "F1 score of logistic regression trained on German dataset without any mitigation = 0.497861\n",
      "Detailed scores for Adult dataset\n",
      "Precision (PPV): 0.584847\n",
      "Recall (TPR): 0.433400\n",
      "Specificity (TNR): 0.903781\n",
      "F1-score: 0.497861\n"
     ]
    }
   ],
   "source": [
    "#Performance Metrics from Adult dataset predictions\n",
    "\n",
    "metric_adult_debiased_test = BinaryLabelDatasetMetric(pred_debiased_test_a, \n",
    "                                             unprivileged_groups=a_unprivileged_groups,\n",
    "                                             privileged_groups=a_privileged_groups)\n",
    "\n",
    "\n",
    "\n",
    "classified_adult_debiased_test = ClassificationMetric(adult_orig_test, \n",
    "                                                 pred_debiased_test_a,\n",
    "                                                 unprivileged_groups=a_unprivileged_groups,\n",
    "                                                 privileged_groups=a_privileged_groups)\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Debiased LR with Adult Test Set Fairness Performance (based on predictions)\"))\n",
    "\n",
    "#Checking Equalized Odds: average odds differecence, which is the avg. of differences in FPR&TPR for privileged and unprivileged groups.\n",
    "deb_aeo_a = classified_adult_debiased_test.average_odds_difference()\n",
    "print(\"Average equalized odds difference between unprivileged and privileged groups = %f\" % deb_aeo_a)\n",
    "\n",
    "#Disparate Impact ratio between privileged and unprivileged groups.\n",
    "deb_di_a = classified_adult_debiased_test.disparate_impact()\n",
    "print(\"Disparate impact ratio between unprivileged and privileged groups = %f\" % deb_di_a)\n",
    "\n",
    "#Demographic parity difference between privileged and unprivileged groups.\n",
    "deb_spd_a = classified_adult_debiased_test.statistical_parity_difference()\n",
    "print(\"Demographic parity difference between unprivileged and privileged groups = %f\" % deb_spd_a)\n",
    "\n",
    "#Predictive parity difference: PPV difference between privileged and unprivileged groups.\n",
    "deb_ppd_a = classified_adult_debiased_test.positive_predictive_value(privileged=False) - classified_adult_debiased_test.positive_predictive_value(privileged=True)\n",
    "print(\"Predictive Parity difference between unprivileged and privileged groups = %f\" % deb_ppd_a)\n",
    "\n",
    "#Individual Fairness: 1)Consistency, 2) Euclidean Distance between individuals.\n",
    "print(\"Consistency of indivuals' predicted labels = %f\" % metric_adult_debiased_test.consistency())\n",
    "\n",
    "\n",
    "#Prediction performance metrics\n",
    "TPRa = classified_adult_debiased_test.true_positive_rate() #recall\n",
    "TNRa = classified_adult_debiased_test.true_negative_rate() #specificity\n",
    "PPVa = classified_adult_debiased_test.positive_predictive_value() #precision\n",
    "bal_acc_a = (TPRa+TNRa)/2\n",
    "f1_a = 2*((PPVa*TPRa)/(PPVa+TPRa))\n",
    "\n",
    "display(Markdown(\"#### Debiased LR with Adult Test Set Prediction Performance\"))\n",
    "print(\"Standard accuracy of logistic regression trained on German dataset without any mitigation = %f\" % classified_adult_debiased_test.accuracy())\n",
    "print(\"Balanced accuracy of logistic regression trained on German dataset without any mitigation = %f\" % bal_acc_a)\n",
    "print(\"F1 score of logistic regression trained on German dataset without any mitigation = %f\" % f1_a)\n",
    "\n",
    "print(\"Detailed scores for Adult dataset\")\n",
    "print(\"Precision (PPV): %f\" %PPVa)\n",
    "print(\"Recall (TPR): %f\" %TPRa)\n",
    "print(\"Specificity (TNR): %f\" %TNRa)\n",
    "print(\"F1-score: %f\" %f1_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x24cbcb9c550>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_adult = confusion_matrix(adult_orig_test.labels, pred_debiased_test_a.labels)\n",
    "\n",
    "disp_adult = ConfusionMatrixDisplay(confusion_matrix=cm_adult)\n",
    "disp_adult.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.746716; batch adversarial loss: 0.689986\n",
      "epoch 1; iter: 0; batch classifier loss: 0.686425; batch adversarial loss: 0.670758\n",
      "epoch 2; iter: 0; batch classifier loss: 0.605644; batch adversarial loss: 0.686718\n",
      "epoch 3; iter: 0; batch classifier loss: 0.617251; batch adversarial loss: 0.664385\n",
      "epoch 4; iter: 0; batch classifier loss: 0.591867; batch adversarial loss: 0.666315\n",
      "epoch 5; iter: 0; batch classifier loss: 0.533945; batch adversarial loss: 0.683485\n",
      "epoch 6; iter: 0; batch classifier loss: 0.581868; batch adversarial loss: 0.658815\n",
      "epoch 7; iter: 0; batch classifier loss: 0.547423; batch adversarial loss: 0.671008\n",
      "epoch 8; iter: 0; batch classifier loss: 0.587933; batch adversarial loss: 0.613524\n",
      "epoch 9; iter: 0; batch classifier loss: 0.545257; batch adversarial loss: 0.669455\n",
      "epoch 10; iter: 0; batch classifier loss: 0.532506; batch adversarial loss: 0.653805\n",
      "epoch 11; iter: 0; batch classifier loss: 0.486039; batch adversarial loss: 0.662835\n",
      "epoch 12; iter: 0; batch classifier loss: 0.572186; batch adversarial loss: 0.640990\n",
      "epoch 13; iter: 0; batch classifier loss: 0.519840; batch adversarial loss: 0.652326\n",
      "epoch 14; iter: 0; batch classifier loss: 0.587776; batch adversarial loss: 0.649916\n",
      "epoch 15; iter: 0; batch classifier loss: 0.461740; batch adversarial loss: 0.639194\n",
      "epoch 16; iter: 0; batch classifier loss: 0.593895; batch adversarial loss: 0.643197\n",
      "epoch 17; iter: 0; batch classifier loss: 0.535696; batch adversarial loss: 0.627556\n",
      "epoch 18; iter: 0; batch classifier loss: 0.535228; batch adversarial loss: 0.647279\n",
      "epoch 19; iter: 0; batch classifier loss: 0.551716; batch adversarial loss: 0.651366\n",
      "epoch 20; iter: 0; batch classifier loss: 0.592060; batch adversarial loss: 0.630770\n",
      "epoch 21; iter: 0; batch classifier loss: 0.490198; batch adversarial loss: 0.611489\n",
      "epoch 22; iter: 0; batch classifier loss: 0.578690; batch adversarial loss: 0.626719\n",
      "epoch 23; iter: 0; batch classifier loss: 0.555845; batch adversarial loss: 0.586559\n",
      "epoch 24; iter: 0; batch classifier loss: 0.534132; batch adversarial loss: 0.637327\n",
      "epoch 25; iter: 0; batch classifier loss: 0.544895; batch adversarial loss: 0.603733\n",
      "epoch 26; iter: 0; batch classifier loss: 0.554105; batch adversarial loss: 0.605296\n",
      "epoch 27; iter: 0; batch classifier loss: 0.581203; batch adversarial loss: 0.611553\n",
      "epoch 28; iter: 0; batch classifier loss: 0.559759; batch adversarial loss: 0.604962\n",
      "epoch 29; iter: 0; batch classifier loss: 0.645262; batch adversarial loss: 0.625306\n",
      "epoch 30; iter: 0; batch classifier loss: 0.467467; batch adversarial loss: 0.586512\n",
      "epoch 31; iter: 0; batch classifier loss: 0.564148; batch adversarial loss: 0.601605\n",
      "epoch 32; iter: 0; batch classifier loss: 0.531805; batch adversarial loss: 0.568419\n",
      "epoch 33; iter: 0; batch classifier loss: 0.606758; batch adversarial loss: 0.592282\n",
      "epoch 34; iter: 0; batch classifier loss: 0.617191; batch adversarial loss: 0.579984\n",
      "epoch 35; iter: 0; batch classifier loss: 0.555571; batch adversarial loss: 0.608455\n",
      "epoch 36; iter: 0; batch classifier loss: 0.512149; batch adversarial loss: 0.567965\n",
      "epoch 37; iter: 0; batch classifier loss: 0.565496; batch adversarial loss: 0.553713\n",
      "epoch 38; iter: 0; batch classifier loss: 0.558749; batch adversarial loss: 0.549407\n",
      "epoch 39; iter: 0; batch classifier loss: 0.491238; batch adversarial loss: 0.593270\n",
      "epoch 40; iter: 0; batch classifier loss: 0.537248; batch adversarial loss: 0.554471\n",
      "epoch 41; iter: 0; batch classifier loss: 0.537119; batch adversarial loss: 0.559440\n",
      "epoch 42; iter: 0; batch classifier loss: 0.586837; batch adversarial loss: 0.546914\n",
      "epoch 43; iter: 0; batch classifier loss: 0.554350; batch adversarial loss: 0.553074\n",
      "epoch 44; iter: 0; batch classifier loss: 0.587073; batch adversarial loss: 0.580736\n",
      "epoch 45; iter: 0; batch classifier loss: 0.549151; batch adversarial loss: 0.579406\n",
      "epoch 46; iter: 0; batch classifier loss: 0.489261; batch adversarial loss: 0.568290\n",
      "epoch 47; iter: 0; batch classifier loss: 0.557103; batch adversarial loss: 0.579409\n",
      "epoch 48; iter: 0; batch classifier loss: 0.551092; batch adversarial loss: 0.604424\n",
      "epoch 49; iter: 0; batch classifier loss: 0.501426; batch adversarial loss: 0.609001\n"
     ]
    }
   ],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "#Debiasing model for German dataset\n",
    "german_model = AdversarialDebiasing(privileged_groups = g_privileged_groups,\n",
    "                          unprivileged_groups = g_unprivileged_groups,\n",
    "                          scope_name='debiased_german_classifier',\n",
    "                          debias=True,\n",
    "                          sess=sess)\n",
    "\n",
    "\n",
    "german_model.fit(german_orig_train)\n",
    "\n",
    "#pred_debiased_train_g = german_model.predict(german_orig_train)\n",
    "pred_debiased_test_g = german_model.predict(german_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               instance weights            features                            \\\n",
       "                                protected attribute                             \n",
       "                                                age  sex credit_history=Delay   \n",
       "instance names                                                                  \n",
       "135                         1.0                 1.0  0.0            -0.303387   \n",
       "392                         1.0                 1.0  1.0            -0.303387   \n",
       "14                          1.0                 1.0  0.0            -0.303387   \n",
       "721                         1.0                 0.0  0.0            -0.303387   \n",
       "773                         1.0                 1.0  1.0            -0.303387   \n",
       "...                         ...                 ...  ...                  ...   \n",
       "871                         1.0                 1.0  1.0            -0.303387   \n",
       "444                         1.0                 1.0  0.0            -0.303387   \n",
       "542                         1.0                 1.0  1.0            -0.303387   \n",
       "95                          1.0                 1.0  1.0            -0.303387   \n",
       "462                         1.0                 1.0  0.0            -0.303387   \n",
       "\n",
       "                                                                           \\\n",
       "                                                                            \n",
       "               credit_history=None/Paid credit_history=Other savings=500+   \n",
       "instance names                                                              \n",
       "135                           -1.300887             1.575623    -0.348991   \n",
       "392                            0.768706            -0.634670    -0.348991   \n",
       "14                             0.768706            -0.634670    -0.348991   \n",
       "721                            0.768706            -0.634670     2.865402   \n",
       "773                           -1.300887             1.575623    -0.348991   \n",
       "...                                 ...                  ...          ...   \n",
       "871                           -1.300887             1.575623    -0.348991   \n",
       "444                           -1.300887             1.575623    -0.348991   \n",
       "542                            0.768706            -0.634670    -0.348991   \n",
       "95                             0.768706            -0.634670    -0.348991   \n",
       "462                            0.768706            -0.634670    -0.348991   \n",
       "\n",
       "                                                                       \\\n",
       "                                                                        \n",
       "               savings=<500 savings=Unknown/None employment=1-4 years   \n",
       "instance names                                                          \n",
       "135               -1.615007             2.220856            -0.988636   \n",
       "392                0.619192            -0.450277            -0.988636   \n",
       "14                 0.619192            -0.450277             1.011495   \n",
       "721               -1.615007            -0.450277             1.011495   \n",
       "773                0.619192            -0.450277            -0.988636   \n",
       "...                     ...                  ...                  ...   \n",
       "871                0.619192            -0.450277            -0.988636   \n",
       "444                0.619192            -0.450277             1.011495   \n",
       "542               -1.615007             2.220856            -0.988636   \n",
       "95                 0.619192            -0.450277             1.011495   \n",
       "462                0.619192            -0.450277             1.011495   \n",
       "\n",
       "                                                         labels  \n",
       "                                                                 \n",
       "               employment=4+ years employment=Unemployed         \n",
       "instance names                                                   \n",
       "135                       1.141329              -0.27735    1.0  \n",
       "392                       1.141329              -0.27735    1.0  \n",
       "14                       -0.876172              -0.27735    0.0  \n",
       "721                      -0.876172              -0.27735    1.0  \n",
       "773                       1.141329              -0.27735    1.0  \n",
       "...                            ...                   ...    ...  \n",
       "871                       1.141329              -0.27735    1.0  \n",
       "444                      -0.876172              -0.27735    1.0  \n",
       "542                       1.141329              -0.27735    1.0  \n",
       "95                       -0.876172              -0.27735    1.0  \n",
       "462                      -0.876172              -0.27735    0.0  \n",
       "\n",
       "[300 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_debiased_test_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Debiased LR with German Test Set Fairness Performance (based on predictions)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average equalized odds difference between unprivileged and privileged groups = 0.089572\n",
      "Disparate impact ratio between unprivileged and privileged groups = 1.099099\n",
      "Demographic parity difference between unprivileged and privileged groups = 0.090164\n",
      "Predictive Parity difference between unprivileged and privileged groups = -0.220721\n",
      "Consistency of indivuals' predicted labels = 0.992667\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Debiased LR with German Test Set Prediction Performance"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard accuracy of logistic regression trained on German dataset without any mitigation = 0.646667\n",
      "Balanced accuracy of logistic regression trained on German dataset without any mitigation = 0.492034\n",
      "F1 score of logistic regression trained on German dataset without any mitigation = 0.780083\n",
      "Detailed scores for german dataset\n",
      "Precision (PPV): 0.676259\n",
      "Recall (TPR): 0.921569\n",
      "Specificity (TNR): 0.062500\n",
      "F1-score: 0.780083\n"
     ]
    }
   ],
   "source": [
    "#Performance Metrics from German dataset predictions\n",
    "\n",
    "metric_german_debiased_test = BinaryLabelDatasetMetric(pred_debiased_test_g, \n",
    "                                             unprivileged_groups=g_unprivileged_groups,\n",
    "                                             privileged_groups=g_privileged_groups)\n",
    "\n",
    "\n",
    "\n",
    "classified_german_debiased_test = ClassificationMetric(german_orig_test, \n",
    "                                                 pred_debiased_test_g,\n",
    "                                                 unprivileged_groups=g_unprivileged_groups,\n",
    "                                                 privileged_groups=g_privileged_groups)\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Debiased LR with German Test Set Fairness Performance (based on predictions)\"))\n",
    "\n",
    "#Checking Equalized Odds: average odds differecence, which is the avg. of differences in FPR&TPR for privileged and unprivileged groups.\n",
    "deb_aeo_g = classified_german_debiased_test.average_odds_difference()\n",
    "print(\"Average equalized odds difference between unprivileged and privileged groups = %f\" % deb_aeo_g)\n",
    "\n",
    "#Disparate Impact ratio between privileged and unprivileged groups.\n",
    "deb_di_g = classified_german_debiased_test.disparate_impact()\n",
    "print(\"Disparate impact ratio between unprivileged and privileged groups = %f\" % deb_di_g)\n",
    "\n",
    "#Demographic parity difference between privileged and unprivileged groups.\n",
    "deb_spd_g = classified_german_debiased_test.statistical_parity_difference()\n",
    "print(\"Demographic parity difference between unprivileged and privileged groups = %f\" % deb_spd_g)\n",
    "\n",
    "#Predictive parity difference: PPV difference between privileged and unprivileged groups.\n",
    "deb_ppd_g = classified_german_debiased_test.positive_predictive_value(privileged=False) - classified_german_debiased_test.positive_predictive_value(privileged=True)\n",
    "print(\"Predictive Parity difference between unprivileged and privileged groups = %f\" % deb_ppd_g)\n",
    "\n",
    "#Individual Fairness: 1)Consistency, 2) Euclidean Distance between individuals.\n",
    "print(\"Consistency of indivuals' predicted labels = %f\" % metric_german_debiased_test.consistency())\n",
    "\n",
    "\n",
    "#Prediction performance metrics\n",
    "TPRg = classified_german_debiased_test.true_positive_rate() #recall\n",
    "TNRg = classified_german_debiased_test.true_negative_rate() #specificity\n",
    "PPVg = classified_german_debiased_test.positive_predictive_value() #precision\n",
    "bal_acc_g = (TPRg+TNRg)/2\n",
    "f1_g = 2*((PPVg*TPRg)/(PPVg+TPRg))\n",
    "\n",
    "display(Markdown(\"#### Debiased LR with German Test Set Prediction Performance\"))\n",
    "print(\"Standard accuracy of logistic regression trained on German dataset without any mitigation = %f\" % classified_german_debiased_test.accuracy())\n",
    "print(\"Balanced accuracy of logistic regression trained on German dataset without any mitigation = %f\" % bal_acc_g)\n",
    "print(\"F1 score of logistic regression trained on German dataset without any mitigation = %f\" % f1_g)\n",
    "\n",
    "print(\"Detailed scores for german dataset\")\n",
    "print(\"Precision (PPV): %f\" %PPVg)\n",
    "print(\"Recall (TPR): %f\" %TPRg)\n",
    "print(\"Specificity (TNR): %f\" %TNRg)\n",
    "print(\"F1-score: %f\" %f1_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x24cc1781c88>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_german = confusion_matrix(german_orig_test.labels, pred_debiased_test_g.labels)\n",
    "\n",
    "disp_german = ConfusionMatrixDisplay(confusion_matrix=cm_german)\n",
    "disp_german.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aif360",
   "language": "python",
   "name": "aif360"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

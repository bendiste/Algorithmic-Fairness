%!TEX root = ../COSCFair.tex
\section{The COSCFair Framework} \label{sec:framework}

In this section, we explain how the COSCFair framework is constructed and introduce the type of components used to implement each step. Our framework consists of four main steps and components. It starts with pre-processing step for the dataset, where we identify the \textbf{subgroup IDs} of each sample. Then, we apply a clustering algorithm on the training set to discover the natural groups (clusters) it contains, where the samples in each of these groups are closer to each other than the others. The next step is dividing the training set into \textbf{cluster sets}, where the training samples are grouped according to their cluster IDs. Then, we oversample each of these cluster sets based on the subgroup IDs of the samples to achieve an equal number of samples for each subgroup that exists in the cluster. The final step is the classification step, where the classifier training and class label predictions of the test set occur. Here, we have studied three possible strategies for classifier training and label prediction, which are discussed further in Section \ref{ssec:str_classf}. The pseudocode of COSCFair is given in Algorithm \ref{alg1}.

\input{pseudocode.tex}\label{alg1}


\subsection{Data Preparation}\label{ssec:dataprep}

The data preparation step consists of several sub-steps, which are identifying the subgroup IDs, adding this information as a new variable to the dataset, and splitting the dataset as training and test. However, identifying the subgroup labels of each sample is one of the most important components of the framework, which we will discuss here in more detail. The subgroups in datasets are discovered based on the total number of binary sensitive attributes and the binary decision label, which corresponds to 2\textsuperscript{n}. In our experiments, we have two binary sensitive attributes and one binary class label in all the datasets, which corresponds to eight subgroups per dataset. Without considering the class labels (2\textsuperscript{n-1}), these subgroups are later identified as the privileged and unprivileged subgroups. For example, there are four main subgroups in each dataset that we use in our experiments.

There are two base groups that are always privileged or unprivileged. If a subgroup has unfavorable values in both sensitive attributes, that subgroup becomes the most unprivileged subgroup in the dataset. If a subgroup has favorable values for both sensitive attributes, then that subgroup becomes the most privileged subgroup. The other subgroups that have different combinations of favorable and unfavorable values for different sensitive attributes should be interpreted as both potentially privileged and unprivileged subgroups. Thus, while investigating their position in a dataset, they should be tested as both privileged and unprivileged groups (see Table \ref{Table5}).

After the subgroup ID variable is added, the sensitive attributes are removed from the dataset since the new subgroup IDs contain information regarding these sensitive attributes. Finally, if a dataset contains a set of numerical variables, these variables should be standardized in training and test sets separately so that they will not have domination over other variables in clustering and classification steps.


\subsection{Clustering}\label{ssec:clust}

Clustering step in COSCFair framework is implemented with the \textbf{fuzzy c-means clustering} \cite{fuzzyc}, which is a soft clustering algorithm that allows each sample in a dataset to be assigned to more than one cluster. In fuzzy clustering, each sample belongs to a cluster with a certain probability which adds up to 1 in total. The algorithm works with the core idea of assigning the samples to clusters in a way that the samples in the same cluster are as similar as possible, while the samples in different clusters are as dissimilar as possible. Clusters are formed based on a distance measure (such as Euclidean distance), which is used to calculate (and minimize sum of) the distances between the samples and the assigned cluster centroids. Thus, it is important to apply standardization on the numerical features of the datasets in data preparation step to prevent the unjustified domination these features.

Fuzzy c-means requires the number of clusters to be given as an input. Thus, we run the fuzzy c-means multiple times using predefined list of values for the number of clusters. In each run, compute the \textbf{fuzzy partition coefficient} (FPC) and the \textbf{silhouette score}. We choose the number that yields the best combination of these two values as the optimal number of clusters. Before using fuzzy c-means, it is recommended to use a dimensionality reduction technique such as principal component analysis (PCA) if the whole dataset consists of numerical variables, or the Factor Analysis of Mixed Data (FAMD) if the dataset consists of both categorical and numerical variables.

\subsection{Oversampling}\label{ssec:oversamp}

After splitting the training set into cluster sets using the cluster memberships of training samples, we oversample each cluster set, where the oversampling criterion is the subgroup IDs of the samples(2\textsuperscript{n}). We use subgroup IDs to oversample so that we can obtain an equal representation for each subgroup in each cluster, where they all have precisely the same number of samples with both positive and negative outcomes. We use Synthetic Minority Oversampling Technique (SMOTE) \cite{smote} to oversample our cluster sets, although different oversampling algorithms can also be used in this step. SMOTE creates new synthetic samples by drawing a line in between two samples that are closer to each other in feature space that belongs to the class which needs to be oversampled, then it produces the synthetic samples along these lines. Since these synthetic samples are created based on the line between two existing samples, these two samples must be close enough to each other to ensure good quality of synthetic sample production. Therefore, we cluster the training set into smaller cluster sets where the samples used for oversampling in these clusters are closer to each other, which decreases the distances between the samples that belong to the same subgroup for a better quality of oversampling procedure.

The main reason why oversampling is used to mitigate bias is because most of the datasets containing bias are actually imbalanced, where different subgroups are not represented equally in terms of number of positive and negative samples per subgroup. This problem can easily be spotted on Table \ref{Table2} in all of the datasets. The most privileged subgroups have the most number of samples in German and Adult datasets, in which of these samples have more positive class labeled samples than other subgroups. This situation is different in COMPAS dataset, where the most privileged group has the least number of samples while the most unprivileged group has the most. However, it is important to note that while all other subgroups have more positive labeled samples, the most unprivileged group has more negative labeled sentences, which is still an imbalance problem that requires oversampling for equal representation of each subgroup with both positive and negative outcomes. 

\input{Tables/Table2}

\subsection{Classification}\label{ssec:str_classf}

In this step, a classification algorithm of choice or multiple classification algorithms of the same type (i.e. logistic regression) are trained depending on the strategy that will be followed. After the classifiers are trained, the class labels of the test set are predicted. However, every strategy has its own unique prediction procedure, which will be described in detail in their respective sections. We should note that during classifier training and test set prediction, the sensitive attributes and the subgroup IDs are not used, which ensures \textit{Fairness Through Unawareness}.

\stitle{Strategy 1:} This strategy is the most similar one to the mainstream classification training and prediction. After each cluster set is oversampled, they are concatenated back together to form a single large training set. Then, only one classifier is trained with this training set and the class labels are predicted based on only this classifier.

\stitle{Strategy 2:} This strategy requires training multiple classifiers, which means that one classifier will be trained based on each oversampled cluster set. Before the class labels of the test set are predicted, each sample's cluster membership is predicted by using the fuzzy c-means clustering object created in the second step. The clustering object will retrieve the ID of a cluster for the sample in which the sample has the highest probability of membership. At the beginning of this process, the classifiers that are trained based on the cluster sets which do not contain samples from the same subgroup as the test sample are discarded. After that, the remaining classifiers are considered for the rest of the process. Next, the classifier object that is trained based on the cluster set which has the same ID as the predicted cluster ID for the given test sample is used to predict the class label of that sample.

\stitle{Strategy 3:} Similar to the second strategy, our final strategy also requires training multiple classifiers using the oversampled cluster sets. However, instead of choosing one classifier this time, all the trained classifiers are taken into consideration while predicting the class label of a test sample. First, the fuzzy c-means clustering object is used to retrieve the probabilities of the test sample belonging to each cluster. After that, some of the cluster IDs are discarded if their cluster sets did not contain samples from the same subgroup as the test sample. Next, the classifiers are trained with the remaining cluster sets. Finally, in the prediction step, the cluster membership probabilities of a sample that are retrieved for the remaining clusters are used as a weight for the predicted class label from each corresponding classifier. The weighting is applied to the predicted outcomes by dividing the probability of each eligible cluster \textit{c} by the sum of the probabilities of all eligible clusters and multiplying it with the predicted outcome of the classifier that is trained with the cluster set having the same ID as the cluster \textit{c}. Then, all of the weighted prediction values are summed into a single value. If this value is greater or equal to 0.5, the weighted prediction label becomes 1, otherwise 0. Our experimental results show that the best strategy for COSCFair framework is Strategy3, and thus it is used in the final comparison with the other baseline methods.
% This weighing process can be formulated as: 
% \[\sum_{i=0}^{i_{clusts}}[(Prob_{cluster_{i}}/\sum_{n=0}^{n_{clusts}}Prob_{cluster_{n}})*PredictedLabel_{classifier_{i}}]\]

% Where i\textsubscript{clusts} indicates the number of eligible clusters left after some of the clusters are discarded and it is equal to n\textsubscript{clusts}. 


